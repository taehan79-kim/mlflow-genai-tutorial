{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Step 0: í™˜ê²½ ì„¤ì • ë° Baseline RAG Agent êµ¬ì¶•\n",
    "\n",
    "## ëª©í‘œ\n",
    "- MLflow ì„¤ì¹˜ ë° ê¸°ë³¸ í™˜ê²½ ì„¤ì •\n",
    "- LangGraph ê¸°ë°˜ RAG Agent êµ¬í˜„ (MLflow ì—†ì´)\n",
    "- ë²¤ì¹˜ë§ˆí¬ìš© baseline ì„±ëŠ¥ í™•ì¸\n",
    "\n",
    "## í•™ìŠµ í¬ì¸íŠ¸\n",
    "- LangGraph Stateì™€ Node ê°œë…\n",
    "- RAG íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ êµ¬ì¡°\n",
    "- ì„±ëŠ¥ ì¸¡ì • ê¸°ì¤€ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "\n",
    "### 1.1 í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”\n",
    "# !pip install mlflow==2.21.3\n",
    "# !pip install langchain==0.3.12\n",
    "# !pip install langchain-openai==0.2.14\n",
    "# !pip install langchain-community==0.3.12\n",
    "# !pip install langgraph==0.2.63\n",
    "# !pip install faiss-cpu==1.9.0\n",
    "# !pip install python-dotenv==1.0.1\n",
    "# !pip install tiktoken==0.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import TypedDict, List, Annotated\n",
    "from operator import add\n",
    "\n",
    "from langchain_aws import ChatBedrock, BedrockEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ìƒ˜í”Œ ë¬¸ì„œ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒ˜í”Œ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 5ê°œì˜ ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± (ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œ)\n",
    "sample_documents = [\n",
    "    \"\"\"\n",
    "    RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\n",
    "    FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤.\n",
    "    Vector StoreëŠ” ìœ ì‚¬ë„ ê²€ìƒ‰(Similarity Search)ì„ í†µí•´ ì¿¼ë¦¬ì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ëƒ…ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "    ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ì—£ì§€ëŠ” ë…¸ë“œ ê°„ì˜ ì „í™˜ ì¡°ê±´ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "    OpenAIì˜ text-embedding-3-small, text-embedding-3-large ëª¨ë¸ì´ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    ì¢‹ì€ ì„ë² ë”©ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "    ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "    ì¼ë°˜ì ìœ¼ë¡œ 512~1024 í† í° í¬ê¸°ì˜ chunkê°€ ë§ì´ ì‚¬ìš©ë˜ë©°, ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ë¶„í• ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(sample_documents)}ê°œì˜ ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store êµ¬ì¶•\n",
    "\n",
    "ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ê³  FAISS Vector Storeì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì´ 5ê°œì˜ chunk ìƒì„±\n",
      "ğŸ”„ Vector Store ìƒì„± ì¤‘...\n",
      "âœ… Vector Store ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œë¥¼ Document ê°ì²´ë¡œ ë³€í™˜\n",
    "documents = [Document(page_content=doc.strip()) for doc in sample_documents]\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "print(f\"ğŸ“„ ì´ {len(split_documents)}ê°œì˜ chunk ìƒì„±\")\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=os.environ[\"AWS_EMD_MODEL_ID\"],\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    region_name=os.environ[\"AWS_REGION\"],\n",
    ")\n",
    "\n",
    "# Vector Store ìƒì„±\n",
    "print(\"ğŸ”„ Vector Store ìƒì„± ì¤‘...\")\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… Vector Store ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LangGraph State ì •ì˜\n",
    "\n",
    "RAG Agentì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•  TypedDictë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAGState ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class RAGState(TypedDict):\n",
    "    \"\"\"RAG Agentì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    query: str                           # ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    retrieved_documents: List[Document]  # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤\n",
    "    context: str                         # ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©í•œ ì»¨í…ìŠ¤íŠ¸\n",
    "    answer: str                          # ìµœì¢… ìƒì„±ëœ ë‹µë³€\n",
    "    metadata: dict                       # ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì‹¤í–‰ ì‹œê°„ ë“±)\n",
    "\n",
    "print(\"âœ… RAGState ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG Agent Nodes êµ¬í˜„\n",
    "\n",
    "### 5.1 Retriever Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retriever Node êµ¬í˜„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def retriever_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"\n",
    "    Vector Storeì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë…¸ë“œ\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: '{state['query']}'\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Vector Storeì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (top_k=3)\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query=state[\"query\"],\n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    retrieval_time = time.time() - start_time\n",
    "    \n",
    "    # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    state[\"retrieved_documents\"] = retrieved_docs\n",
    "    state[\"metadata\"][\"retrieval_time\"] = retrieval_time\n",
    "    state[\"metadata\"][\"num_retrieved_docs\"] = len(retrieved_docs)\n",
    "    \n",
    "    print(f\"âœ… [Retriever] {len(retrieved_docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ ({retrieval_time:.3f}ì´ˆ)\")\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°\n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        preview = doc.page_content[:100].replace(\"\\n\", \" \")\n",
    "        print(f\"  ğŸ“„ ë¬¸ì„œ {i}: {preview}...\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Retriever Node êµ¬í˜„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Generator Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generator Node êµ¬í˜„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def generator_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ\n",
    "    \"\"\"\n",
    "    print(\"\\nâœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[ë¬¸ì„œ {i+1}]\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(state[\"retrieved_documents\"])\n",
    "    ])\n",
    "    state[\"context\"] = context\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ì—†ìœ¼ë©´ \"ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "ì»¨í…ìŠ¤íŠ¸:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {query}\n",
    "\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # LLM ì´ˆê¸°í™”\n",
    "    llm = ChatBedrock(\n",
    "        model_id=os.environ[\"AWS_MODEL_ID\"],\n",
    "        aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        region_name=os.environ[\"AWS_REGION\"],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ\n",
    "    messages = prompt_template.format_messages(\n",
    "        context=context,\n",
    "        query=state[\"query\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    answer = response.content\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    state[\"answer\"] = answer\n",
    "    state[\"metadata\"][\"generation_time\"] = generation_time\n",
    "    state[\"metadata\"][\"llm_model\"] = os.environ[\"AWS_MODEL_ID\"]\n",
    "    \n",
    "    print(f\"âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.3f}ì´ˆ)\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Generator Node êµ¬í˜„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangGraph êµ¬ì„±\n",
    "\n",
    "Retrieverì™€ Generator ë…¸ë“œë¥¼ ì—°ê²°í•˜ì—¬ RAG ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ê·¸ë˜í”„ êµ¬ì¡°:\n",
      "  START â†’ Retriever â†’ Generator â†’ END\n"
     ]
    }
   ],
   "source": [
    "# StateGraph ì´ˆê¸°í™”\n",
    "workflow = StateGraph(RAGState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"generator\", generator_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.add_edge(START, \"retriever\")      # ì‹œì‘ -> Retriever\n",
    "workflow.add_edge(\"retriever\", \"generator\") # Retriever -> Generator\n",
    "workflow.add_edge(\"generator\", END)         # Generator -> ì¢…ë£Œ\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "rag_agent = workflow.compile()\n",
    "\n",
    "print(\"âœ… RAG ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“Š ê·¸ë˜í”„ êµ¬ì¡°:\")\n",
    "print(\"  START â†’ Retriever â†’ Generator â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG Agent ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### 7.1 í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 4ê°œì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ë“¤\n",
    "test_queries = [\n",
    "    \"RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"Vector Storeì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"LangGraphëŠ” ì–´ë–¤ í”„ë ˆì„ì›Œí¬ì¸ê°€ìš”?\",\n",
    "    \"Embeddingê³¼ Chunkingì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(test_queries)}ê°œì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.102ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.     ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.     ê°...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (4.579ì´ˆ)\n"
     ]
    }
   ],
   "source": [
    "def run_rag_agent(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    RAG Graphë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸš€ RAG ì‹¤í–‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": [],\n",
    "        \"context\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"metadata\": {}\n",
    "    }\n",
    "    \n",
    "    # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n",
    "    overall_start = time.time()\n",
    "    \n",
    "    # RAG Agent ì‹¤í–‰\n",
    "    final_state = rag_agent.invoke(initial_state)\n",
    "    \n",
    "    overall_time = time.time() - overall_start\n",
    "    final_state[\"metadata\"][\"overall_time\"] = overall_time\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸\n",
    "result = run_rag_agent(test_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“‹ ì‹¤í–‰ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "RAGì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰**: ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì •í™•í•œ ë‹µë³€ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ìµœì‹  ì •ë³´ í™œìš©**: ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì¦‰, RAGëŠ” LLMì´ ìì²´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ì˜ì¡´í•˜ì§€ ì•Šê³ , í•„ìš”í•œ ì •ë³´ë¥¼ ì™¸ë¶€ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­\n",
      "--------------------------------------------------------------------------------\n",
      "  â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: 4.684ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ ì‹œê°„: 0.102ì´ˆ\n",
      "  â€¢ ìƒì„± ì‹œê°„: 4.579ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 3ê°œ\n",
      "  â€¢ ì‚¬ìš©ëœ LLM: global.anthropic.claude-sonnet-4-5-20250929-v1:0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ (ìš”ì•½)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [1] RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.     ì´ ë°©ë²•ì€ ëª¨...\n",
      "\n",
      "  [2] LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.     ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.     ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ì—£ì§€ëŠ” ë…¸ë“œ ê°„ì˜ ì „í™˜ ì¡°ê±´ì„ ì •ì˜í•©ë‹ˆë‹¤....\n",
      "\n",
      "  [3] Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~1024 í† í° í¬ê¸°ì˜ chunkê°€ ë§ì´ ì‚¬ìš©ë˜ë©°, ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ë¶„í• ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤....\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_result(result: dict):\n",
    "    \"\"\"\n",
    "    RAG ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“‹ ì‹¤í–‰ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nâ“ ì§ˆë¬¸: {result['query']}\")\n",
    "    print(f\"\\nğŸ’¬ ë‹µë³€:\\n{result['answer']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    metadata = result['metadata']\n",
    "    print(f\"  â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: {metadata['overall_time']:.3f}ì´ˆ\")\n",
    "    print(f\"  â€¢ ê²€ìƒ‰ ì‹œê°„: {metadata['retrieval_time']:.3f}ì´ˆ\")\n",
    "    print(f\"  â€¢ ìƒì„± ì‹œê°„: {metadata['generation_time']:.3f}ì´ˆ\")\n",
    "    print(f\"  â€¢ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {metadata['num_retrieved_docs']}ê°œ\")\n",
    "    print(f\"  â€¢ ì‚¬ìš©ëœ LLM: {metadata['llm_model']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ (ìš”ì•½)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, doc in enumerate(result['retrieved_documents'], 1):\n",
    "        preview = doc.page_content[:150].replace(\"\\n\", \" \")\n",
    "        print(f\"\\n  [{i}] {preview}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ì—¬ëŸ¬ ì¿¼ë¦¬ ë°°ì¹˜ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 1/4\n",
      "================================================================================\n",
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.100ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.     ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.     ê°...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (6.690ì´ˆ)\n",
      "\n",
      "âœ… ì™„ë£Œ - ì „ì²´ ì‹œê°„: 6.793ì´ˆ\n",
      "ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "RAGì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. *...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 2/4\n",
      "================================================================================\n",
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'Vector Storeì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.112ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.     FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤. ...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     OpenAIì˜ text-embedding-3-small, text-embedding-3-lar...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (3.979ì´ˆ)\n",
      "\n",
      "âœ… ì™„ë£Œ - ì „ì²´ ì‹œê°„: 4.094ì´ˆ\n",
      "ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: Vector Storeì˜ ì—­í• ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì„ë² ë”© ë²¡í„° ì €ì¥**: ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¹ ë¥¸ ê²€ìƒ‰**: ìœ ì‚¬ë„ ê²€...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 3/4\n",
      "================================================================================\n",
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'LangGraphëŠ” ì–´ë–¤ í”„ë ˆì„ì›Œí¬ì¸ê°€ìš”?'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.096ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.     ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.     ê°...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     OpenAIì˜ text-embedding-3-small, text-embedding-3-lar...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (3.388ì´ˆ)\n",
      "\n",
      "âœ… ì™„ë£Œ - ì „ì²´ ì‹œê°„: 3.487ì´ˆ\n",
      "ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©°, ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 4/4\n",
      "================================================================================\n",
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'Embeddingê³¼ Chunkingì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.095ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     OpenAIì˜ text-embedding-3-small, text-embedding-3-lar...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.     FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤. ...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (5.665ì´ˆ)\n",
      "\n",
      "âœ… ì™„ë£Œ - ì „ì²´ ì‹œê°„: 5.764ì´ˆ\n",
      "ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: Embeddingê³¼ Chunkingì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**Embedding (ì„ë² ë”©)**\n",
      "- í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "- OpenAIì˜ te...\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰\n",
    "all_results = []\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ {i}/{len(test_queries)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    result = run_rag_agent(query)\n",
    "    all_results.append(result)\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ê²°ê³¼ë§Œ ì¶œë ¥\n",
    "    print(f\"\\nâœ… ì™„ë£Œ - ì „ì²´ ì‹œê°„: {result['metadata']['overall_time']:.3f}ì´ˆ\")\n",
    "    print(f\"ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {result['answer'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìš”ì•½\n",
    "\n",
    "ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ baseline ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š Baseline RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰: 4ê°œ ì¿¼ë¦¬\n",
      "\n",
      "â±ï¸  í‰ê·  ì‹¤í–‰ ì‹œê°„:\n",
      "  â€¢ ì „ì²´: 5.035ì´ˆ (Â± 1.517)\n",
      "  â€¢ ê²€ìƒ‰: 0.101ì´ˆ (Â± 0.008)\n",
      "  â€¢ ìƒì„±: 4.930ì´ˆ (Â± 1.519)\n",
      "\n",
      "âš¡ ìµœì†Œ/ìµœëŒ€ ì‹¤í–‰ ì‹œê°„:\n",
      "  â€¢ ìµœì†Œ: 3.487ì´ˆ\n",
      "  â€¢ ìµœëŒ€: 6.793ì´ˆ\n",
      "\n",
      "ğŸ¯ ì„¤ì •:\n",
      "  â€¢ Embedding Model: amazon.titan-embed-text-v2:0\n",
      "  â€¢ LLM Model: global.anthropic.claude-sonnet-4-5-20250929-v1:0\n",
      "  â€¢ Top-K: 3\n",
      "  â€¢ Chunk Size: 512\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘\n",
    "overall_times = [r['metadata']['overall_time'] for r in all_results]\n",
    "retrieval_times = [r['metadata']['retrieval_time'] for r in all_results]\n",
    "generation_times = [r['metadata']['generation_time'] for r in all_results]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š Baseline RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰: {len(all_results)}ê°œ ì¿¼ë¦¬\")\n",
    "print(f\"\\nâ±ï¸  í‰ê·  ì‹¤í–‰ ì‹œê°„:\")\n",
    "print(f\"  â€¢ ì „ì²´: {statistics.mean(overall_times):.3f}ì´ˆ (Â± {statistics.stdev(overall_times):.3f})\")\n",
    "print(f\"  â€¢ ê²€ìƒ‰: {statistics.mean(retrieval_times):.3f}ì´ˆ (Â± {statistics.stdev(retrieval_times):.3f})\")\n",
    "print(f\"  â€¢ ìƒì„±: {statistics.mean(generation_times):.3f}ì´ˆ (Â± {statistics.stdev(generation_times):.3f})\")\n",
    "\n",
    "print(f\"\\nâš¡ ìµœì†Œ/ìµœëŒ€ ì‹¤í–‰ ì‹œê°„:\")\n",
    "print(f\"  â€¢ ìµœì†Œ: {min(overall_times):.3f}ì´ˆ\")\n",
    "print(f\"  â€¢ ìµœëŒ€: {max(overall_times):.3f}ì´ˆ\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì„¤ì •:\")\n",
    "print(f\"  â€¢ Embedding Model: {os.environ[\"AWS_EMD_MODEL_ID\"]}\")\n",
    "print(f\"  â€¢ LLM Model: {result['metadata']['llm_model']}\")\n",
    "print(f\"  â€¢ Top-K: 3\")\n",
    "print(f\"  â€¢ Chunk Size: 512\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ìƒì„¸ ê²°ê³¼ í™•ì¸ (ì„ íƒ)\n",
    "\n",
    "íŠ¹ì • ì¿¼ë¦¬ì˜ ì „ì²´ ê²°ê³¼ë¥¼ ìì„¸íˆ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“‹ ì‹¤í–‰ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "RAGì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰**: ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì •í™•í•œ ë‹µë³€ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ìµœì‹  ì •ë³´ í™œìš©**: ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì¦‰, RAGëŠ” LLMì´ ìì²´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ì˜ì¡´í•˜ì§€ ì•Šê³ , í•„ìš”í•œ ì •ë³´ë¥¼ ì™¸ë¶€ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­\n",
      "--------------------------------------------------------------------------------\n",
      "  â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: 6.793ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ ì‹œê°„: 0.100ì´ˆ\n",
      "  â€¢ ìƒì„± ì‹œê°„: 6.690ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 3ê°œ\n",
      "  â€¢ ì‚¬ìš©ëœ LLM: global.anthropic.claude-sonnet-4-5-20250929-v1:0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ (ìš”ì•½)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [1] RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.     ì´ ë°©ë²•ì€ ëª¨...\n",
      "\n",
      "  [2] LangGraphëŠ” LangChain ìœ„ì— êµ¬ì¶•ëœ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.     ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•í•œ ìƒíƒœì™€ ë…¸ë“œë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.     ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ì—£ì§€ëŠ” ë…¸ë“œ ê°„ì˜ ì „í™˜ ì¡°ê±´ì„ ì •ì˜í•©ë‹ˆë‹¤....\n",
      "\n",
      "  [3] Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~1024 í† í° í¬ê¸°ì˜ chunkê°€ ë§ì´ ì‚¬ìš©ë˜ë©°, ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ë¶„í• ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤....\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë²ˆì§¸ ê²°ê³¼ ìƒì„¸ ì¶œë ¥\n",
    "print_result(all_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ (ì„ íƒ)\n",
    "\n",
    "ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ RAG Agentë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ RAG ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "ğŸ” [Retriever] ê²€ìƒ‰ ì‹œì‘: 'Embeddingì€ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œê°€ìš”?'\n",
      "âœ… [Retriever] 3ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (0.104ì´ˆ)\n",
      "  ğŸ“„ ë¬¸ì„œ 1: EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     OpenAIì˜ text-embedding-3-small, text-embedding-3-lar...\n",
      "  ğŸ“„ ë¬¸ì„œ 2: Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.     FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤. ...\n",
      "  ğŸ“„ ë¬¸ì„œ 3: Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~...\n",
      "\n",
      "âœï¸ [Generator] ë‹µë³€ ìƒì„± ì‹œì‘\n",
      "âœ… [Generator] ë‹µë³€ ìƒì„± ì™„ë£Œ (5.159ì´ˆ)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‹ ì‹¤í–‰ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: Embeddingì€ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œê°€ìš”?\n",
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "Embeddingì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "\n",
      "**Embeddingì´ ì¤‘ìš”í•œ ì´ìœ :**\n",
      "\n",
      "1. **ì˜ë¯¸ì  ìœ ì‚¬ì„± í‘œí˜„**: ì¢‹ì€ ì„ë² ë”©ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜ì‹œì¼œ, í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **íš¨ìœ¨ì ì¸ ê²€ìƒ‰**: Vector Storeì™€ ê²°í•©í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰(Similarity Search)ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ì¿¼ë¦¬ì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **RAG ì‹œìŠ¤í…œì˜ í•µì‹¬**: ë¬¸ì„œë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ ê¸°ë°˜ ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "\n",
      "í˜„ì¬ OpenAIì˜ text-embedding-3-small, text-embedding-3-large ëª¨ë¸ì´ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­\n",
      "--------------------------------------------------------------------------------\n",
      "  â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: 5.272ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ ì‹œê°„: 0.104ì´ˆ\n",
      "  â€¢ ìƒì„± ì‹œê°„: 5.159ì´ˆ\n",
      "  â€¢ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 3ê°œ\n",
      "  â€¢ ì‚¬ìš©ëœ LLM: global.anthropic.claude-sonnet-4-5-20250929-v1:0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ (ìš”ì•½)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [1] EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.     OpenAIì˜ text-embedding-3-small, text-embedding-3-large ëª¨ë¸ì´ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.     ì¢‹ì€ ì„ë² ë”©ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ê³µê°„ì—...\n",
      "\n",
      "  [2] Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.     FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤.     Vector StoreëŠ” ìœ ì‚¬ë„ ê²€ìƒ‰(Similarity Search)ì„ í†µí•´ ì¿¼ë¦¬...\n",
      "\n",
      "  [3] Chunkingì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.     ì ì ˆí•œ chunk í¬ê¸°ëŠ” ê²€ìƒ‰ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì–‘ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.     ì¼ë°˜ì ìœ¼ë¡œ 512~1024 í† í° í¬ê¸°ì˜ chunkê°€ ë§ì´ ì‚¬ìš©ë˜ë©°, ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ë¶„í• ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤....\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì»¤ìŠ¤í…€ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "custom_query = \"Embeddingì€ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œê°€ìš”?\"  # ì›í•˜ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "custom_result = run_rag_agent(custom_query)\n",
    "print_result(custom_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œí•œ ì‘ì—…\n",
    "1. MLflow ë° LangGraph í™˜ê²½ ì„¤ì •\n",
    "2. ìƒ˜í”Œ ë¬¸ì„œë¡œ Vector Store êµ¬ì¶•\n",
    "3. LangGraph ê¸°ë°˜ RAG Agent êµ¬í˜„\n",
    "4. Baseline ì„±ëŠ¥ ì¸¡ì • ë° ë²¤ì¹˜ë§ˆí¬\n",
    "\n",
    "### ğŸ“Š Baseline ì„±ëŠ¥ ì§€í‘œ\n",
    "- í‰ê·  ì‘ë‹µ ì‹œê°„: ~Xì´ˆ\n",
    "- ê²€ìƒ‰ ì‹œê°„: ~Xì´ˆ\n",
    "- ìƒì„± ì‹œê°„: ~Xì´ˆ\n",
    "- ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜: 3ê°œ\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Step 1)\n",
    "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œëŠ” **MLflow Tracking**ì„ ë„ì…í•˜ì—¬:\n",
    "- ì‹¤í—˜ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ê¸°ë¡\n",
    "- Parameters, Metrics, Artifacts ê´€ë¦¬\n",
    "- MLflow UIì—ì„œ ì‹œê°í™”\n",
    "- ì—¬ëŸ¬ ì‹¤í—˜ ê°„ ë¹„êµ ë¶„ì„\n",
    "\n",
    "â†’ `01_mlflow_tracking_basics.ipynb`ë¡œ ê³„ì†í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/)\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "- [LangGraph Tutorial](https://langchain-ai.github.io/langgraph/)\n",
    "- [FAISS Documentation](https://faiss.ai/)\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-genai-tutorial (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
