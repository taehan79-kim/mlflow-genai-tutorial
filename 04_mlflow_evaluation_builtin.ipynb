{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Step 4: MLflow Evaluation - Built-in Scorers\n",
    "\n",
    "## ëª©í‘œ\n",
    "- MLflowì˜ Built-in LLM í‰ê°€ ë©”íŠ¸ë¦­ ì‚¬ìš©\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "- ìë™ í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "## í•™ìŠµ í¬ì¸íŠ¸\n",
    "- Built-in Scorer ì¢…ë¥˜ì™€ ìš©ë„\n",
    "- LLM-as-Judge ê°œë…\n",
    "- Evaluation Dataset êµ¬ì¡°\n",
    "- `mlflow.genai.evaluate()` API\n",
    "- í‰ê°€ ê²°ê³¼ ì¶”ì  ë° ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ì‚¬ì „ ì¤€ë¹„\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "ì´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê¸° ì „ì—:\n",
    "- **Step 0, 1, 2, 3** ì™„ë£Œ ê¶Œì¥\n",
    "- `.env` íŒŒì¼ ì„¤ì • ì™„ë£Œ\n",
    "- í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "\n",
    "### 1.1 í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n",
      "MLflow ë²„ì „: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import SpanType\n",
    "\n",
    "# MLflow GenAI Evaluation\n",
    "from mlflow.genai.scorers import (\n",
    "    Correctness,\n",
    "    RelevanceToQuery,\n",
    "    Guidelines,\n",
    ")\n",
    "from mlflow.genai import scorer\n",
    "\n",
    "# LangChain\n",
    "from langchain_aws import ChatBedrock, BedrockEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "print(f\"MLflow ë²„ì „: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow Tracking ì„¤ì •\n",
    "\n",
    "### 2.1 Tracking URI ë° Experiment ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MLflow ì„¤ì • ì™„ë£Œ\n",
      "ğŸ“Š Experiment Name: rag_agent_evaluation\n",
      "ğŸ†” Experiment ID: 483631771709821094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hank_kim/Documents/taehan/mlflow-genai-tutorial/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:177: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Tracking URI ì„¤ì •\n",
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "\n",
    "# Experiment ì„¤ì •\n",
    "experiment_name = \"rag_agent_evaluation\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "print(\"âœ… MLflow ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ğŸ“Š Experiment Name: {experiment.name}\")\n",
    "print(f\"ğŸ†” Experiment ID: {experiment.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG Agent ì¤€ë¹„\n",
    "\n",
    "### 3.1 ìƒ˜í”Œ ë¬¸ì„œ ë° Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector Store ìƒì„± ì™„ë£Œ (4ê°œ chunks)\n"
     ]
    }
   ],
   "source": [
    "# AWS í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "AWS_MODEL_ID = os.getenv(\"AWS_MODEL_ID\")\n",
    "AWS_EMD_MODEL_ID = os.getenv(\"AWS_EMD_MODEL_ID\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"ap-northeast-2\")\n",
    "\n",
    "# ìƒ˜í”Œ ë¬¸ì„œ\n",
    "sample_documents = [\n",
    "    \"\"\"\n",
    "    RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\n",
    "    FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤.\n",
    "    Vector StoreëŠ” ìœ ì‚¬ë„ ê²€ìƒ‰(Similarity Search)ì„ í†µí•´ ì¿¼ë¦¬ì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ëƒ…ë‹ˆë‹¤.\n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë‚˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë“±ì˜ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    MLflowëŠ” ê¸°ê³„ í•™ìŠµ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼ì…ë‹ˆë‹¤.\n",
    "    ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë²„ì „ ê´€ë¦¬, ë°°í¬ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    MLflow Tracingì„ ì‚¬ìš©í•˜ë©´ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Evaluationì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í’ˆì§ˆì„ ì¸¡ì •í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "    Faithfulness, Relevance, Correctness ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    LLM-as-Judge ë°©ì‹ì€ ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "# Vector Store ìƒì„±\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "documents = [Document(page_content=doc.strip()) for doc in sample_documents]\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# ì„ë² ë”© ë° Vector Store ìƒì„±\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=AWS_EMD_MODEL_ID,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "print(f\"âœ… Vector Store ìƒì„± ì™„ë£Œ ({len(split_docs)}ê°œ chunks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RAG Agent í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… RAG Agent ì •ì˜ ì™„ë£Œ\n",
      "\n",
      "ğŸ’¬ í…ŒìŠ¤íŠ¸ ë‹µë³€:\n",
      "RAG(Retrieval-Augmented Generation)ëŠ” **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ **ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰**: ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì •í™•í•œ ë‹µë³€ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ìµœì‹  ì •ë³´ í™œìš©**: ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì¦‰, RAGëŠ” LLMì´ ìì²´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ì˜ì¡´í•˜ì§€ ì•Šê³ , í•„ìš”í•  ë•Œ ì™¸ë¶€ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def simple_rag_agent(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ê°„ë‹¨í•œ RAG Agent êµ¬í˜„\n",
    "    í‰ê°€ìš©ìœ¼ë¡œ ì‚¬ìš©í•  ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # 1. ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "    \n",
    "    # 2. Context ìƒì„±\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # 3. Prompt ìƒì„±\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"human\", \"ì»¨í…ìŠ¤íŠ¸:\\n{context}\\n\\nì§ˆë¬¸: {query}\\n\\në‹µë³€:\")\n",
    "    ])\n",
    "    \n",
    "    messages = prompt_template.format_messages(context=context, query=query)\n",
    "    \n",
    "    # 4. LLM í˜¸ì¶œ\n",
    "    llm = ChatBedrock(\n",
    "        model_id=AWS_MODEL_ID,\n",
    "        region_name=AWS_REGION,\n",
    "        model_kwargs={\"temperature\": 0.7}\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_answer = simple_rag_agent(\"RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "print(\"\\nâœ… RAG Agent ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"\\nğŸ’¬ í…ŒìŠ¤íŠ¸ ë‹µë³€:\\n{test_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Dataset ì¤€ë¹„\n",
    "\n",
    "### 4.1 Dataset êµ¬ì¡° ì´í•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“š Evaluation Dataset êµ¬ì¡°\n",
      "================================================================================\n",
      "\n",
      "MLflowì˜ Evaluation Datasetì€ ë‹¤ìŒ ì»¬ëŸ¼ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. inputs (í•„ìˆ˜):\n",
      "   - ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°\n",
      "   - Dict í˜•íƒœ: {\"query\": \"ì§ˆë¬¸\"} ë˜ëŠ” {\"question\": \"ì§ˆë¬¸\"}\n",
      "   - predict_fnì˜ ì¸ìì™€ ë§¤ì¹­ë¨\n",
      "\n",
      "2. expectations (ì„ íƒ, ê¶Œì¥):\n",
      "   - Ground truth ë˜ëŠ” ê¸°ëŒ€ ê²°ê³¼\n",
      "   - Correctness ë“± ë¹„êµ í‰ê°€ì— ì‚¬ìš©\n",
      "   - Dict í˜•íƒœ: {\"expected_response\": \"ì •ë‹µ\"}\n",
      "\n",
      "3. outputs (ì„ íƒ):\n",
      "   - ì´ë¯¸ ìƒì„±ëœ ì‘ë‹µ (predict_fn ì—†ì´ í‰ê°€ ì‹œ)\n",
      "   - Dict ë˜ëŠ” String\n",
      "\n",
      "4. ê¸°íƒ€ ë©”íƒ€ë°ì´í„° (ì„ íƒ):\n",
      "   - í‰ê°€ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´\n",
      "   - ì˜ˆ: {\"retrieved_documents\": [...]}\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“š Evaluation Dataset êµ¬ì¡°\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "MLflowì˜ Evaluation Datasetì€ ë‹¤ìŒ ì»¬ëŸ¼ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. inputs (í•„ìˆ˜):\n",
    "   - ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°\n",
    "   - Dict í˜•íƒœ: {\"query\": \"ì§ˆë¬¸\"} ë˜ëŠ” {\"question\": \"ì§ˆë¬¸\"}\n",
    "   - predict_fnì˜ ì¸ìì™€ ë§¤ì¹­ë¨\n",
    "\n",
    "2. expectations (ì„ íƒ, ê¶Œì¥):\n",
    "   - Ground truth ë˜ëŠ” ê¸°ëŒ€ ê²°ê³¼\n",
    "   - Correctness ë“± ë¹„êµ í‰ê°€ì— ì‚¬ìš©\n",
    "   - Dict í˜•íƒœ: {\"expected_response\": \"ì •ë‹µ\"}\n",
    "\n",
    "3. outputs (ì„ íƒ):\n",
    "   - ì´ë¯¸ ìƒì„±ëœ ì‘ë‹µ (predict_fn ì—†ì´ í‰ê°€ ì‹œ)\n",
    "   - Dict ë˜ëŠ” String\n",
    "\n",
    "4. ê¸°íƒ€ ë©”íƒ€ë°ì´í„° (ì„ íƒ):\n",
    "   - í‰ê°€ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´\n",
    "   - ì˜ˆ: {\"retrieved_documents\": [...]}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation Dataset ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Evaluation Dataset ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š Dataset í¬ê¸°: 4ê°œ\n",
      "\n",
      "================================================================================\n",
      "Dataset ë¯¸ë¦¬ë³´ê¸°:\n",
      "================================================================================\n",
      "                                  inputs\n",
      "0               {'query': 'RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?'}\n",
      "1  {'query': 'Vector StoreëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?'}\n",
      "2    {'query': 'MLflow Tracingì´ ë¬´ì—‡ì¸ê°€ìš”?'}\n",
      "3      {'query': 'LLM-as-Judgeë€ ë¬´ì—‡ì¸ê°€ìš”?'}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Dataset ì •ì˜\n",
    "eval_data = [\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìë¡œ, ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ë‹µë³€ ìƒì„± ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Vector StoreëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Vector StoreëŠ” ë¬¸ì„œë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ì¿¼ë¦¬ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"MLflow Tracingì´ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ Span ë‹¨ìœ„ë¡œ ì¶”ì í•˜ì—¬ ì„±ëŠ¥ê³¼ ë™ì‘ì„ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"LLM-as-Judgeë€ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"LLM-as-JudgeëŠ” ë‹¤ë¥¸ LLMì„ í™œìš©í•˜ì—¬ AI ì‘ë‹µì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, Faithfulness, Relevance ë“±ì˜ ë©”íŠ¸ë¦­ì„ í‰ê°€í•©ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "eval_dataset = pd.DataFrame(eval_data)\n",
    "\n",
    "print(\"\\nâœ… Evaluation Dataset ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"\\nğŸ“Š Dataset í¬ê¸°: {len(eval_dataset)}ê°œ\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(\"=\"*80)\n",
    "print(eval_dataset[['inputs']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Built-in Scorers ì´í•´\n",
    "\n",
    "### 5.1 ì£¼ìš” Built-in Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ MLflow Built-in Scorers\n",
      "================================================================================\n",
      "Scorer               | ì„¤ëª…                                       | ì…ë ¥                   | ì¶œë ¥             \n",
      "-------------------- | ---------------------------------------- | -------------------- | ---------------\n",
      "Correctness          | ì˜ˆìƒ ë‹µë³€ê³¼ ì‹¤ì œ ë‹µë³€ ë¹„êµ                          | outputs, expectations | 0-1 ì ìˆ˜         \n",
      "RelevanceToQuery     | ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ì§€ í‰ê°€                         | inputs, outputs      | 0-1 ì ìˆ˜         \n",
      "Guidelines           | ì»¤ìŠ¤í…€ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ì—¬ë¶€                          | outputs, guidelines  | Boolean/ì ìˆ˜     \n",
      "Safety               | ìœ í•´ ì½˜í…ì¸  ê°ì§€                                | outputs              | Boolean        \n",
      "RetrievalGroundedness | ê²€ìƒ‰ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± í™•ì¸                        | outputs, retrieved_docs | 0-1 ì ìˆ˜         \n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ ëª¨ë“  ScorerëŠ” LLM-as-Judge ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "   ê¸°ë³¸ Judge Model: gpt-4o-mini (ë³€ê²½ ê°€ëŠ¥)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ MLflow Built-in Scorers\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scorers_info = [\n",
    "    [\"Scorer\", \"ì„¤ëª…\", \"ì…ë ¥\", \"ì¶œë ¥\"],\n",
    "    [\"-\" * 20, \"-\" * 40, \"-\" * 20, \"-\" * 15],\n",
    "    [\n",
    "        \"Correctness\",\n",
    "        \"ì˜ˆìƒ ë‹µë³€ê³¼ ì‹¤ì œ ë‹µë³€ ë¹„êµ\",\n",
    "        \"outputs, expectations\",\n",
    "        \"0-1 ì ìˆ˜\"\n",
    "    ],\n",
    "    [\n",
    "        \"RelevanceToQuery\",\n",
    "        \"ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ì§€ í‰ê°€\",\n",
    "        \"inputs, outputs\",\n",
    "        \"0-1 ì ìˆ˜\"\n",
    "    ],\n",
    "    [\n",
    "        \"Guidelines\",\n",
    "        \"ì»¤ìŠ¤í…€ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ì—¬ë¶€\",\n",
    "        \"outputs, guidelines\",\n",
    "        \"Boolean/ì ìˆ˜\"\n",
    "    ],\n",
    "    [\n",
    "        \"Safety\",\n",
    "        \"ìœ í•´ ì½˜í…ì¸  ê°ì§€\",\n",
    "        \"outputs\",\n",
    "        \"Boolean\"\n",
    "    ],\n",
    "    [\n",
    "        \"RetrievalGroundedness\",\n",
    "        \"ê²€ìƒ‰ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± í™•ì¸\",\n",
    "        \"outputs, retrieved_docs\",\n",
    "        \"0-1 ì ìˆ˜\"\n",
    "    ],\n",
    "]\n",
    "\n",
    "for row in scorers_info:\n",
    "    print(f\"{row[0]:<20} | {row[1]:<40} | {row[2]:<20} | {row[3]:<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ ëª¨ë“  ScorerëŠ” LLM-as-Judge ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "print(\"   ê¸°ë³¸ Judge Model: gpt-4o-mini (ë³€ê²½ ê°€ëŠ¥)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Scorer ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Scorers ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ì´ 3ê°œì˜ Scorer ì •ì˜:\n",
      "  â€¢ correctness\n",
      "  â€¢ relevance\n",
      "  â€¢ is_korean\n"
     ]
    }
   ],
   "source": [
    "# Built-in Scorers ì •ì˜\n",
    "scorers = [\n",
    "    Correctness(\n",
    "        name=\"correctness\",\n",
    "        model=f\"bedrock:/{AWS_MODEL_ID}\",  # Judge LLM ì§€ì •\n",
    "    ),\n",
    "    RelevanceToQuery(\n",
    "        name=\"relevance\",\n",
    "        model=f\"bedrock:/{AWS_MODEL_ID}\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"is_korean\",\n",
    "        guidelines=\"ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "        model=f\"bedrock:/{AWS_MODEL_ID}\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"\\nâœ… Scorers ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"\\nğŸ“Š ì´ {len(scorers)}ê°œì˜ Scorer ì •ì˜:\")\n",
    "for _scorer in scorers:\n",
    "    print(f\"  â€¢ {_scorer.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í‰ê°€ ì‹¤í–‰\n",
    "\n",
    "### 6.1 mlflow.genai.evaluate() ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ í‰ê°€ ì‹¤í–‰ ì‹œì‘\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# predict_fn ë˜í•‘ (mlflow.genai.evaluateê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)\n",
    "def predict_fn(*, query: str) -> str:\n",
    "    \"\"\"\n",
    "    MLflow evaluationì„ ìœ„í•œ ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "    \n",
    "    ì¤‘ìš”: MLflowëŠ” inputs dictë¥¼ í‚¤ì›Œë“œ ì¸ìë¡œ ì–¸íŒ©í•˜ë¯€ë¡œ\n",
    "    í‚¤ì›Œë“œ ì „ìš© ì¸ì(*)ë¡œ ì •ì˜í•´ì•¼ í•¨\n",
    "    inputs={\"query\": \"...\"} -> predict_fn(query=\"...\")\n",
    "    \"\"\"\n",
    "    return simple_rag_agent(query)\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=predict_fn,\n",
    "    scorers=scorers,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… í‰ê°€ ì™„ë£Œ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 í‰ê°€ ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­ ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ ì§‘ê³„ ë©”íŠ¸ë¦­:\n",
      "  â€¢ relevance/mean: 1.000\n",
      "  â€¢ correctness/mean: 0.750\n",
      "  â€¢ is_korean/mean: 1.000\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­ ìš”ì•½\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì „ì²´ ë©”íŠ¸ë¦­\n",
    "metrics = results.metrics\n",
    "\n",
    "print(\"\\nğŸ“ˆ ì§‘ê³„ ë©”íŠ¸ë¦­:\")\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  â€¢ {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  â€¢ {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ìƒì„¸ í‰ê°€ ê²°ê³¼ í…Œì´ë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>correctness/value</th>\n",
       "      <th>is_korean/value</th>\n",
       "      <th>expected_response/value</th>\n",
       "      <th>relevance/value</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-ae4b37d361a68c28543abb3e6c76aab2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìë¡œ, ì™¸ë¶€ ì§€...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-ae4b37d361a68c28543a...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766024892010</td>\n",
       "      <td>4317</td>\n",
       "      <td>{'body': '{\"anthropic_version\": \"bedrock-2023-...</td>\n",
       "      <td>{'ResponseMetadata': {'RequestId': 'da15a14b-6...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.eval.requestId': '21584ef0-3728-42e5-...</td>\n",
       "      <td>[{'trace_id': 'rks302GmjChUOrs+bHaqsg==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-b176d0e6eba14aaea99b435d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr-929500295e96c472e96cd58d1f9f85f5</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>LLM-as-JudgeëŠ” ë‹¤ë¥¸ LLMì„ í™œìš©í•˜ì—¬ AI ì‘ë‹µì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-929500295e96c472e96c...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766024892118</td>\n",
       "      <td>3288</td>\n",
       "      <td>{'body': '{\"anthropic_version\": \"bedrock-2023-...</td>\n",
       "      <td>{'ResponseMetadata': {'RequestId': '8f0c971d-8...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.eval.requestId': '6be5f006-4518-4cb9-...</td>\n",
       "      <td>[{'trace_id': 'kpUAKV6WxHLpbNWNH5+F9Q==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-7df6c119b53646a293740eb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr-fc9420d3a4c7d7656b7503ff34c8a7db</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ Span ë‹¨ìœ„ë¡œ ì¶”ì ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-fc9420d3a4c7d7656b75...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766024892119</td>\n",
       "      <td>3628</td>\n",
       "      <td>{'body': '{\"anthropic_version\": \"bedrock-2023-...</td>\n",
       "      <td>{'ResponseMetadata': {'RequestId': 'e776bf45-b...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.eval.requestId': 'cf4dd19e-401d-4ee1-...</td>\n",
       "      <td>[{'trace_id': '/JQg06TH12VrdQP/NMin2w==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-1a44b89488a243a6b30df3ee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr-a7dc77aebf7f65db231d7f8e7a5f717f</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Vector StoreëŠ” ë¬¸ì„œë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ì¿¼ë¦¬ì™€ì˜ ìœ ì‚¬ë„ë¥¼...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-a7dc77aebf7f65db231d...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766024892116</td>\n",
       "      <td>6242</td>\n",
       "      <td>{'body': '{\"anthropic_version\": \"bedrock-2023-...</td>\n",
       "      <td>{'ResponseMetadata': {'RequestId': 'f405a8ee-a...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.eval.requestId': 'd3b07595-8c25-41f2-...</td>\n",
       "      <td>[{'trace_id': 'p9x3rr9/ZdsjHX+Oel9xfw==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-50cc65ca096248a4b26c7eb4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id correctness/value is_korean/value  \\\n",
       "0  tr-ae4b37d361a68c28543abb3e6c76aab2               yes             yes   \n",
       "1  tr-929500295e96c472e96cd58d1f9f85f5               yes             yes   \n",
       "2  tr-fc9420d3a4c7d7656b7503ff34c8a7db                no             yes   \n",
       "3  tr-a7dc77aebf7f65db231d7f8e7a5f717f               yes             yes   \n",
       "\n",
       "                             expected_response/value relevance/value  \\\n",
       "0  RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìë¡œ, ì™¸ë¶€ ì§€...             yes   \n",
       "1  LLM-as-JudgeëŠ” ë‹¤ë¥¸ LLMì„ í™œìš©í•˜ì—¬ AI ì‘ë‹µì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜...             yes   \n",
       "2  MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ Span ë‹¨ìœ„ë¡œ ì¶”ì ...             yes   \n",
       "3  Vector StoreëŠ” ë¬¸ì„œë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ì¿¼ë¦¬ì™€ì˜ ìœ ì‚¬ë„ë¥¼...             yes   \n",
       "\n",
       "                                               trace client_request_id state  \\\n",
       "0  {\"info\": {\"trace_id\": \"tr-ae4b37d361a68c28543a...              None    OK   \n",
       "1  {\"info\": {\"trace_id\": \"tr-929500295e96c472e96c...              None    OK   \n",
       "2  {\"info\": {\"trace_id\": \"tr-fc9420d3a4c7d7656b75...              None    OK   \n",
       "3  {\"info\": {\"trace_id\": \"tr-a7dc77aebf7f65db231d...              None    OK   \n",
       "\n",
       "    request_time  execution_duration  \\\n",
       "0  1766024892010                4317   \n",
       "1  1766024892118                3288   \n",
       "2  1766024892119                3628   \n",
       "3  1766024892116                6242   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'body': '{\"anthropic_version\": \"bedrock-2023-...   \n",
       "1  {'body': '{\"anthropic_version\": \"bedrock-2023-...   \n",
       "2  {'body': '{\"anthropic_version\": \"bedrock-2023-...   \n",
       "3  {'body': '{\"anthropic_version\": \"bedrock-2023-...   \n",
       "\n",
       "                                            response  \\\n",
       "0  {'ResponseMetadata': {'RequestId': 'da15a14b-6...   \n",
       "1  {'ResponseMetadata': {'RequestId': '8f0c971d-8...   \n",
       "2  {'ResponseMetadata': {'RequestId': 'e776bf45-b...   \n",
       "3  {'ResponseMetadata': {'RequestId': 'f405a8ee-a...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "1  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "2  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "3  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.eval.requestId': '21584ef0-3728-42e5-...   \n",
       "1  {'mlflow.eval.requestId': '6be5f006-4518-4cb9-...   \n",
       "2  {'mlflow.eval.requestId': 'cf4dd19e-401d-4ee1-...   \n",
       "3  {'mlflow.eval.requestId': 'd3b07595-8c25-41f2-...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'trace_id': 'rks302GmjChUOrs+bHaqsg==', 'spa...   \n",
       "1  [{'trace_id': 'kpUAKV6WxHLpbNWNH5+F9Q==', 'spa...   \n",
       "2  [{'trace_id': '/JQg06TH12VrdQP/NMin2w==', 'spa...   \n",
       "3  [{'trace_id': 'p9x3rr9/ZdsjHX+Oel9xfw==', 'spa...   \n",
       "\n",
       "                                         assessments  \n",
       "0  [{'assessment_id': 'a-b176d0e6eba14aaea99b435d...  \n",
       "1  [{'assessment_id': 'a-7df6c119b53646a293740eb4...  \n",
       "2  [{'assessment_id': 'a-1a44b89488a243a6b30df3ee...  \n",
       "3  [{'assessment_id': 'a-50cc65ca096248a4b26c7eb4...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸\n",
    "import json\n",
    "\n",
    "eval_results_table = results.result_df\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” Request/Response ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì²« ë²ˆì§¸ rowì˜ request êµ¬ì¡° í™•ì¸\n",
    "first_request = eval_results_table['request'][0]\n",
    "first_response = eval_results_table['response'][0]\n",
    "\n",
    "print(\"\\\\nğŸ“ Request êµ¬ì¡°:\")\n",
    "print(f\"  íƒ€ì…: {type(first_request)}\")\n",
    "print(f\"  í‚¤: {first_request.keys() if isinstance(first_request, dict) else 'N/A'}\")\n",
    "\n",
    "print(\"\\\\nğŸ“ Response êµ¬ì¡°:\")\n",
    "print(f\"  íƒ€ì…: {type(first_response)}\")\n",
    "print(f\"  í‚¤: {first_response.keys() if isinstance(first_response, dict) else 'N/A'}\")\n",
    "\n",
    "# bodyê°€ JSON ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±\n",
    "if 'body' in first_request:\n",
    "    body_parsed = json.loads(first_request['body'])\n",
    "    print(\"\\\\nğŸ“„ Request Body ë‚´ìš© (íŒŒì‹±ë¨):\")\n",
    "    print(f\"  - messages íƒ€ì…: {type(body_parsed.get('messages'))}\")\n",
    "    print(f\"  - messages ê°œìˆ˜: {len(body_parsed.get('messages', []))}\")\n",
    "    if body_parsed.get('messages'):\n",
    "        print(f\"  - ì²« ë©”ì‹œì§€: {body_parsed['messages'][0]['role']}\")\n",
    "        \n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”\n",
    "import json\n",
    "\n",
    "df = results.result_df.copy()\n",
    "\n",
    "def extract_input_from_trace(row):\n",
    "    \"\"\"\n",
    "    Traceì˜ spansì—ì„œ ì‹¤ì œ ì…ë ¥ ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # spans ì»¬ëŸ¼ì—ì„œ ì •ë³´ ì¶”ì¶œ\n",
    "        if 'spans' in row and row['spans']:\n",
    "            # ì²« ë²ˆì§¸ spanì˜ inputs í™•ì¸\n",
    "            first_span = row['spans'][0]\n",
    "            if 'inputs' in first_span:\n",
    "                inputs = first_span.get('inputs', {})\n",
    "                return inputs.get('query', '')\n",
    "        \n",
    "        # ëŒ€ì•ˆ: request bodyì—ì„œ ì¶”ì¶œ\n",
    "        if isinstance(row['request'], dict) and 'body' in row['request']:\n",
    "            body = json.loads(row['request']['body'])\n",
    "            messages = body.get('messages', [])\n",
    "            if messages:\n",
    "                content = messages[0].get('content', '')\n",
    "                # \"ì§ˆë¬¸: xxx\" íŒ¨í„´ì—ì„œ ì¶”ì¶œ\n",
    "                if 'ì§ˆë¬¸:' in content:\n",
    "                    return content.split('ì§ˆë¬¸:', 1)[1].split('ë‹µë³€:', 1)[0].strip()\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def extract_output_from_trace(row):\n",
    "    \"\"\"\n",
    "    Traceì˜ spans ë˜ëŠ” responseì—ì„œ ì‹¤ì œ ì¶œë ¥ ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # spans ì»¬ëŸ¼ì—ì„œ outputs ì¶”ì¶œ\n",
    "        if 'spans' in row and row['spans']:\n",
    "            first_span = row['spans'][0]\n",
    "            if 'outputs' in first_span:\n",
    "                outputs = first_span.get('outputs')\n",
    "                # outputsê°€ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "                if isinstance(outputs, str):\n",
    "                    return outputs\n",
    "                # dictë©´ ì ì ˆí•œ í‚¤ ì°¾ê¸°\n",
    "                elif isinstance(outputs, dict):\n",
    "                    return outputs.get('content', outputs.get('text', str(outputs)))\n",
    "        \n",
    "        # ëŒ€ì•ˆ: response ì»¬ëŸ¼ì—ì„œ ì§ì ‘ ì¶”ì¶œ (Bedrock ì‘ë‹µ êµ¬ì¡°)\n",
    "        if isinstance(row['response'], dict):\n",
    "            # Bedrock ì‘ë‹µ êµ¬ì¡°: output.message.content[0].text\n",
    "            if 'output' in row['response']:\n",
    "                output = row['response']['output']\n",
    "                if 'message' in output:\n",
    "                    content = output['message'].get('content', [])\n",
    "                    if content and len(content) > 0:\n",
    "                        return content[0].get('text', '')\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# ì»¬ëŸ¼ ì¶”ê°€\n",
    "df[\"input\"] = df.apply(extract_input_from_trace, axis=1)\n",
    "df[\"output\"] = df.apply(extract_output_from_trace, axis=1)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“‹ ê° ìƒ˜í”Œë³„ í‰ê°€ ê²°ê³¼\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì£¼ìš” ì»¬ëŸ¼ë§Œ ì¶œë ¥\n",
    "display_columns = [\n",
    "    col for col in df.columns \n",
    "    if any(x in col for x in ['input', 'output', 'correctness', 'relevance', 'is_korean'])\n",
    "]\n",
    "\n",
    "# ê°„ë‹¨í•œ ë¯¸ë¦¬ë³´ê¸°\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"\\\\nìƒ˜í”Œ {idx + 1}:\")\n",
    "    print(f\"  ì§ˆë¬¸: {row['input'][:80]}...\")\n",
    "    print(f\"  ë‹µë³€: {row['output'][:80]}...\")\n",
    "    print(f\"  Correctness: {row.get('correctness/value', 'N/A')}\")\n",
    "    print(f\"  Relevance: {row.get('relevance/value', 'N/A')}\")\n",
    "    print(f\"  Is Korean: {row.get('is_korean/value', 'N/A')}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 ê°œë³„ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” ì²« ë²ˆì§¸ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: MLflow Tracingì´ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ğŸ’¬ ìƒì„±ëœ ë‹µë³€:\n",
      "MLflow Tracingì€ **LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥**ì…ë‹ˆë‹¤.\n",
      "\n",
      "MLflowëŠ” ê¸°ê³„ í•™ìŠµ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼ìœ¼ë¡œ, ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë²„ì „ ê´€ë¦¬, ë°°í¬ ë“±ì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ”ë°, ê·¸ ì¤‘ MLflow Tracingì€ íŠ¹íˆ LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë™ì‘ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "âœ… ê¸°ëŒ€ ë‹µë³€:\n",
      "MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ Span ë‹¨ìœ„ë¡œ ì¶”ì í•˜ì—¬ ì„±ëŠ¥ê³¼ ë™ì‘ì„ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“Š í‰ê°€ ì ìˆ˜:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "CORRECTNESS:\n",
      "  ì ìˆ˜: no\n",
      "\n",
      "RELEVANCE:\n",
      "  ì ìˆ˜: yes\n",
      "\n",
      "IS_KOREAN:\n",
      "  ì ìˆ˜: yes\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë²ˆì§¸ ìƒ˜í”Œ ìƒì„¸ ë³´ê¸°\n",
    "first_row = df.iloc[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” ì²« ë²ˆì§¸ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nâ“ ì§ˆë¬¸: {first_row['input']}\")\n",
    "print(f\"\\nğŸ’¬ ìƒì„±ëœ ë‹µë³€:\\n{first_row['output']}\")\n",
    "print(f\"\\nâœ… ê¸°ëŒ€ ë‹µë³€:\\n{first_row['expected_response/value']}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"ğŸ“Š í‰ê°€ ì ìˆ˜:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Scorerë³„ ì ìˆ˜ ë° Rationale\n",
    "for scorer_name in ['correctness', 'relevance', 'is_korean']:\n",
    "    score_col = f\"{scorer_name}/value\"\n",
    "    # rationale_col = f\"{scorer_name}/rationale\"\n",
    "    \n",
    "    if score_col in first_row:\n",
    "        score = first_row[score_col]\n",
    "        # rationale = first_row.get(rationale_col, \"N/A\")\n",
    "        \n",
    "        print(f\"\\n{scorer_name.upper()}:\")\n",
    "        print(f\"  ì ìˆ˜: {score}\")\n",
    "        # print(f\"  ê·¼ê±°: {rationale}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì»¤ìŠ¤í…€ Scorer ì¶”ê°€\n",
    "\n",
    "### 7.1 ê°„ë‹¨í•œ ì»¤ìŠ¤í…€ Scorer ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì»¤ìŠ¤í…€ Scorer ì •ì˜ ì™„ë£Œ\n",
      "  â€¢ answer_length: ë‹µë³€ ê¸¸ì´ í‰ê°€\n",
      "  â€¢ contains_keywords: í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€\n"
     ]
    }
   ],
   "source": [
    "from mlflow.entities import Feedback\n",
    "from mlflow.genai import scorer\n",
    "\n",
    "@scorer\n",
    "def answer_length(outputs: str) -> Feedback:\n",
    "    length = len(outputs)\n",
    "\n",
    "    if length < 50:\n",
    "        value = \"too_short\"\n",
    "        rationale = f\"ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({length}ì).\"\n",
    "    elif length > 500:\n",
    "        value = \"too_long\"\n",
    "        rationale = f\"ë‹µë³€ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({length}ì).\"\n",
    "    else:\n",
    "        value = \"appropriate\"\n",
    "        rationale = f\"ë‹µë³€ ê¸¸ì´ê°€ ì ì ˆí•©ë‹ˆë‹¤ ({length}ì).\"\n",
    "\n",
    "    return Feedback(\n",
    "        value=value,\n",
    "        rationale=rationale,\n",
    "        metadata={\"length\": length},\n",
    "    )\n",
    "\n",
    "\n",
    "@scorer\n",
    "def contains_keywords(outputs: str, inputs: Dict[str, Any]) -> bool:\n",
    "    \"\"\"\n",
    "    ë‹µë³€ì— ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    \"\"\"\n",
    "    query = inputs.get(\"query\", \"\").lower()\n",
    "    outputs_lower = outputs.lower()\n",
    "    \n",
    "    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)\n",
    "    keywords = [word for word in query.split() if len(word) > 2]\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ë‹µë³€ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€\n",
    "    return any(keyword in outputs_lower for keyword in keywords)\n",
    "\n",
    "\n",
    "print(\"âœ… ì»¤ìŠ¤í…€ Scorer ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"  â€¢ answer_length: ë‹µë³€ ê¸¸ì´ í‰ê°€\")\n",
    "print(\"  â€¢ contains_keywords: í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 ì»¤ìŠ¤í…€ Scorer í¬í•¨í•˜ì—¬ ì¬í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”„ ì»¤ìŠ¤í…€ Scorer í¬í•¨ ì¬í‰ê°€\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ëª¨ë“  Scorer ê²°í•©\n",
    "all_scorers = scorers + [answer_length, contains_keywords]\n",
    "\n",
    "# predict_fnë„ ë™ì¼í•˜ê²Œ í‚¤ì›Œë“œ ì¸ìë¡œ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "def predict_fn_with_custom(*, query: str) -> str:\n",
    "    \"\"\"í‚¤ì›Œë“œ ì „ìš© ì¸ìë¡œ ì •ì˜ëœ predict í•¨ìˆ˜\"\"\"\n",
    "    return simple_rag_agent(query)\n",
    "\n",
    "# ì¬í‰ê°€\n",
    "results_with_custom = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=predict_fn_with_custom,\n",
    "    scorers=all_scorers,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ì¬í‰ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ í™•ì¸\n",
    "print(\"\\nğŸ“Š ì—…ë°ì´íŠ¸ëœ ë©”íŠ¸ë¦­:\")\n",
    "for key, value in results_with_custom.metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  â€¢ {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  â€¢ {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í‰ê°€ ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "### 8.1 ì—¬ëŸ¬ Run ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š Evaluation Runs ë¹„êµ\n",
      "================================================================================\n",
      "\n",
      "Run ID                             Correctness    \n",
      "--------------------------------------------------------------------------------\n",
      "394cb8dcedd44763acadf89a2edab488           0.750\n",
      "3fde436d0c354ce8995fea5e80052ca3           0.000\n",
      "a712e041bff84feeba7ddcb7317a5019           0.750\n",
      "70b656ca03f3443a8cb0016afad7c27f           0.750\n",
      "28427d545efb458fb8d5fe548bf169c9           0.000\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í—˜ì˜ ëª¨ë“  Run ê²€ìƒ‰\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š Evaluation Runs ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Run ID':<35}{'Correctness':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for run in runs[:5]:\n",
    "    run_id = run.info.run_id[:32]\n",
    "    correctness = run.data.metrics.get('correctness/mean', 0)\n",
    "    \n",
    "    print(f\"{run_id:<35} {correctness:>12.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MLflow UIì—ì„œ ê²°ê³¼ í™•ì¸\n",
    "\n",
    "### 9.1 UI íƒìƒ‰ ê°€ì´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸŒ MLflow UIì—ì„œ í‰ê°€ ê²°ê³¼ í™•ì¸í•˜ê¸°\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ MLflow UI ì‹¤í–‰:\n",
      "   $ mlflow ui --port 5000\n",
      "\n",
      "2ï¸âƒ£ Experiment ì„ íƒ:\n",
      "   â€¢ 'rag_agent_evaluation' ì‹¤í—˜ í´ë¦­\n",
      "\n",
      "3ï¸âƒ£ Evaluation Runs í™•ì¸:\n",
      "   â€¢ ê° Runì€ í•˜ë‚˜ì˜ í‰ê°€ ì‹¤í–‰ì„ ë‚˜íƒ€ëƒ„\n",
      "   â€¢ Metrics ì»¬ëŸ¼ì—ì„œ ì§‘ê³„ ì ìˆ˜ í™•ì¸\n",
      "   â€¢ Run ì´ë¦„ìœ¼ë¡œ model_id í™•ì¸\n",
      "\n",
      "4ï¸âƒ£ ê°œë³„ Run ìƒì„¸ ë³´ê¸°:\n",
      "   â€¢ Run í´ë¦­\n",
      "   â€¢ \"Evaluation\" íƒ­ìœ¼ë¡œ ì´ë™\n",
      "   â€¢ ê° ìƒ˜í”Œë³„ ì…ë ¥, ì¶œë ¥, ì ìˆ˜ í™•ì¸\n",
      "\n",
      "5ï¸âƒ£ Scorerë³„ ìƒì„¸ ë¶„ì„:\n",
      "   â€¢ Rationale í™•ì¸ (LLMì´ í‰ê°€í•œ ê·¼ê±°)\n",
      "   â€¢ ì ìˆ˜ ë¶„í¬ ì‹œê°í™”\n",
      "   â€¢ ì‹¤íŒ¨í•œ ìƒ˜í”Œ í•„í„°ë§\n",
      "\n",
      "6ï¸âƒ£ Run ë¹„êµ:\n",
      "   â€¢ ì—¬ëŸ¬ Run ì„ íƒ (ì²´í¬ë°•ìŠ¤)\n",
      "   â€¢ \"Compare\" ë²„íŠ¼ í´ë¦­\n",
      "   â€¢ Metrics ì°¨íŠ¸ë¡œ ë¹„êµ\n",
      "\n",
      "7ï¸âƒ£ Trace í™•ì¸ (ìë™ ìƒì„±):\n",
      "   â€¢ ê° í‰ê°€ ìƒ˜í”Œë§ˆë‹¤ Trace ìƒì„±ë¨\n",
      "   â€¢ \"Traces\" íƒ­ì—ì„œ ì‹¤í–‰ ê³¼ì • í™•ì¸\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸŒ MLflow UIì—ì„œ í‰ê°€ ê²°ê³¼ í™•ì¸í•˜ê¸°\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1ï¸âƒ£ MLflow UI ì‹¤í–‰:\n",
    "   $ mlflow ui --port 5000\n",
    "\n",
    "2ï¸âƒ£ Experiment ì„ íƒ:\n",
    "   â€¢ 'rag_agent_evaluation' ì‹¤í—˜ í´ë¦­\n",
    "\n",
    "3ï¸âƒ£ Evaluation Runs í™•ì¸:\n",
    "   â€¢ ê° Runì€ í•˜ë‚˜ì˜ í‰ê°€ ì‹¤í–‰ì„ ë‚˜íƒ€ëƒ„\n",
    "   â€¢ Metrics ì»¬ëŸ¼ì—ì„œ ì§‘ê³„ ì ìˆ˜ í™•ì¸\n",
    "   â€¢ Run ì´ë¦„ìœ¼ë¡œ model_id í™•ì¸\n",
    "\n",
    "4ï¸âƒ£ ê°œë³„ Run ìƒì„¸ ë³´ê¸°:\n",
    "   â€¢ Run í´ë¦­\n",
    "   â€¢ \"Evaluation\" íƒ­ìœ¼ë¡œ ì´ë™\n",
    "   â€¢ ê° ìƒ˜í”Œë³„ ì…ë ¥, ì¶œë ¥, ì ìˆ˜ í™•ì¸\n",
    "\n",
    "5ï¸âƒ£ Scorerë³„ ìƒì„¸ ë¶„ì„:\n",
    "   â€¢ Rationale í™•ì¸ (LLMì´ í‰ê°€í•œ ê·¼ê±°)\n",
    "   â€¢ ì ìˆ˜ ë¶„í¬ ì‹œê°í™”\n",
    "   â€¢ ì‹¤íŒ¨í•œ ìƒ˜í”Œ í•„í„°ë§\n",
    "\n",
    "6ï¸âƒ£ Run ë¹„êµ:\n",
    "   â€¢ ì—¬ëŸ¬ Run ì„ íƒ (ì²´í¬ë°•ìŠ¤)\n",
    "   â€¢ \"Compare\" ë²„íŠ¼ í´ë¦­\n",
    "   â€¢ Metrics ì°¨íŠ¸ë¡œ ë¹„êµ\n",
    "\n",
    "7ï¸âƒ£ Trace í™•ì¸ (ìë™ ìƒì„±):\n",
    "   â€¢ ê° í‰ê°€ ìƒ˜í”Œë§ˆë‹¤ Trace ìƒì„±ë¨\n",
    "   â€¢ \"Traces\" íƒ­ì—ì„œ ì‹¤í–‰ ê³¼ì • í™•ì¸\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ê³ ê¸‰: ì‚¬ì „ ìƒì„±ëœ ì¶œë ¥ìœ¼ë¡œ í‰ê°€\n",
    "\n",
    "### 10.1 predict_fn ì—†ì´ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94morderly-squirrel-762\u001b[0m\n",
      "  Run ID: \u001b[94m4b97c619ce8e44bfabfd67d801442cbe\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "\n",
      "âœ… ì‚¬ì „ ìƒì„± ì¶œë ¥ í‰ê°€ ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ë©”íŠ¸ë¦­:\n",
      "  â€¢ relevance/mean: 1.000\n",
      "  â€¢ is_korean/mean: 1.000\n",
      "  â€¢ correctness/mean: 0.500\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ì „ì— ìƒì„±ëœ ì‘ë‹µì„ í¬í•¨í•œ ë°ì´í„°ì…‹\n",
    "pregenerated_data = [\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "        \"outputs\": \"RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìì…ë‹ˆë‹¤.\",\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Vector StoreëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "        \"outputs\": \"Vector StoreëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\",\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Vector StoreëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "pregenerated_df = pd.DataFrame(pregenerated_data)\n",
    "\n",
    "# predict_fn ì—†ì´ í‰ê°€\n",
    "results_pregenerated = mlflow.genai.evaluate(\n",
    "    data=pregenerated_df,\n",
    "    # predict_fn ì—†ìŒ - outputs ì»¬ëŸ¼ ì‚¬ìš©\n",
    "    scorers=scorers,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ì‚¬ì „ ìƒì„± ì¶œë ¥ í‰ê°€ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“Š ë©”íŠ¸ë¦­:\")\n",
    "for key, value in results_pregenerated.metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  â€¢ {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  â€¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>is_korean/value</th>\n",
       "      <th>correctness/value</th>\n",
       "      <th>relevance/value</th>\n",
       "      <th>expected_response/value</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-1960a3671341e6766fefce44b1f65edb</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Vector StoreëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-1960a3671341e6766fef...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766023807251</td>\n",
       "      <td>0</td>\n",
       "      <td>{'query': 'Vector StoreëŠ” ë¬´ì—‡ì¸ê°€ìš”?'}</td>\n",
       "      <td>Vector StoreëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.</td>\n",
       "      <td>{'mlflow.trace_schema.version': '3', 'mlflow.u...</td>\n",
       "      <td>{'mlflow.eval.requestId': '2194d9883c7dc13237d...</td>\n",
       "      <td>[{'trace_id': 'GWCjZxNB5nZv785EsfZe2w==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-343adb660fa74edb802a86d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr-1ed92af383eceea8b8a145f38f705748</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì…ë‹ˆë‹¤.</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-1ed92af383eceea8b8a1...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1766023807250</td>\n",
       "      <td>0</td>\n",
       "      <td>{'query': 'RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?'}</td>\n",
       "      <td>RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìì…ë‹ˆë‹¤.</td>\n",
       "      <td>{'mlflow.trace_schema.version': '3', 'mlflow.u...</td>\n",
       "      <td>{'mlflow.eval.requestId': '161a7107e3c32ee5c96...</td>\n",
       "      <td>[{'trace_id': 'Htkq84Ps7qi4oUXzj3BXSA==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-bb7737eaec55403297510906...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id is_korean/value correctness/value  \\\n",
       "0  tr-1960a3671341e6766fefce44b1f65edb             yes               yes   \n",
       "1  tr-1ed92af383eceea8b8a145f38f705748             yes                no   \n",
       "\n",
       "  relevance/value      expected_response/value  \\\n",
       "0             yes  Vector StoreëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.   \n",
       "1             yes         RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì…ë‹ˆë‹¤.   \n",
       "\n",
       "                                               trace client_request_id state  \\\n",
       "0  {\"info\": {\"trace_id\": \"tr-1960a3671341e6766fef...              None    OK   \n",
       "1  {\"info\": {\"trace_id\": \"tr-1ed92af383eceea8b8a1...              None    OK   \n",
       "\n",
       "    request_time  execution_duration                            request  \\\n",
       "0  1766023807251                   0  {'query': 'Vector StoreëŠ” ë¬´ì—‡ì¸ê°€ìš”?'}   \n",
       "1  1766023807250                   0           {'query': 'RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?'}   \n",
       "\n",
       "                                      response  \\\n",
       "0        Vector StoreëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.   \n",
       "1  RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìì…ë‹ˆë‹¤.   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace_schema.version': '3', 'mlflow.u...   \n",
       "1  {'mlflow.trace_schema.version': '3', 'mlflow.u...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.eval.requestId': '2194d9883c7dc13237d...   \n",
       "1  {'mlflow.eval.requestId': '161a7107e3c32ee5c96...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'trace_id': 'GWCjZxNB5nZv785EsfZe2w==', 'spa...   \n",
       "1  [{'trace_id': 'Htkq84Ps7qi4oUXzj3BXSA==', 'spa...   \n",
       "\n",
       "                                         assessments  \n",
       "0  [{'assessment_id': 'a-343adb660fa74edb802a86d9...  \n",
       "1  [{'assessment_id': 'a-bb7737eaec55403297510906...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pregenerated.result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Best Practices\n",
    "\n",
    "### 11.1 í‰ê°€ ëª¨ë²” ì‚¬ë¡€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ MLflow Evaluation Best Practices\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. Dataset ì„¤ê³„:\n",
    "   âœ… ë‹¤ì–‘í•œ ì¿¼ë¦¬ íƒ€ì… í¬í•¨ (ê°„ë‹¨í•œ ì§ˆë¬¸, ë³µì¡í•œ ì§ˆë¬¸)\n",
    "   âœ… Edge case í¬í•¨ (ëª¨í˜¸í•œ ì§ˆë¬¸, ì˜ëª»ëœ ì§ˆë¬¸)\n",
    "   âœ… Ground truth í’ˆì§ˆ í™•ë³´ (ì „ë¬¸ê°€ ê²€í† )\n",
    "   âœ… ìµœì†Œ 20-50ê°œ ìƒ˜í”Œ (í†µê³„ì  ìœ ì˜ì„±)\n",
    "\n",
    "2. Scorer ì„ íƒ:\n",
    "   âœ… ëª©ì ì— ë§ëŠ” Scorer ì¡°í•©\n",
    "   âœ… Correctness + RelevanceëŠ” ê¸°ë³¸\n",
    "   âœ… ë„ë©”ì¸ë³„ ì»¤ìŠ¤í…€ Scorer ì¶”ê°€\n",
    "   âœ… Guidelinesë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦\n",
    "\n",
    "3. Judge Model ì„ íƒ:\n",
    "   âœ… gpt-4o-mini: ë¹ ë¥´ê³  ì €ë ´ (ê¸°ë³¸ ê¶Œì¥)\n",
    "   âœ… gpt-4o: ë” ì •í™•í•œ í‰ê°€ í•„ìš” ì‹œ\n",
    "   âœ… claude-opus-4: ëŒ€ì•ˆ LLM\n",
    "\n",
    "4. í‰ê°€ ì‹¤í–‰:\n",
    "   âœ… ì—¬ëŸ¬ ë²„ì „ìœ¼ë¡œ A/B í…ŒìŠ¤íŠ¸\n",
    "   âœ… model_idë¡œ ëª…í™•í•œ ë²„ì „ ê´€ë¦¬\n",
    "   âœ… ì •ê¸°ì ì¸ ì¬í‰ê°€ (ë°ì´í„° ë³€ê²½ ì‹œ)\n",
    "\n",
    "5. ê²°ê³¼ ë¶„ì„:\n",
    "   âœ… ë‚®ì€ ì ìˆ˜ ìƒ˜í”Œ ì§‘ì¤‘ ë¶„ì„\n",
    "   âœ… Rationale ê²€í†  (ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€)\n",
    "   âœ… Trace í™•ì¸ (ì‹¤í–‰ ê³¼ì • ë””ë²„ê¹…)\n",
    "   âœ… íŒ¨í„´ ë°œê²¬ ë° ê°œì„ \n",
    "\n",
    "6. ë¹„ìš© ìµœì í™”:\n",
    "   âœ… ìƒ˜í”Œ ìˆ˜ ì ì ˆíˆ ì¡°ì ˆ\n",
    "   âœ… Judge model ì„ íƒ (mini vs full)\n",
    "   âœ… ìºì‹± í™œìš© (ë™ì¼ ì…ë ¥ ì¬í‰ê°€)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œí•œ ì‘ì—…\n",
    "1. Evaluation Dataset ì¤€ë¹„ ë° êµ¬ì¡° ì´í•´\n",
    "2. Built-in Scorers ì‚¬ìš© (Correctness, RelevanceToQuery, Guidelines)\n",
    "3. mlflow.genai.evaluate() APIë¡œ ìë™ í‰ê°€ ì‹¤í–‰\n",
    "4. ì»¤ìŠ¤í…€ Scorer ì •ì˜ ë° ì¶”ê°€\n",
    "5. í‰ê°€ ê²°ê³¼ ë¶„ì„ ë° ë¹„êµ\n",
    "6. MLflow UIì—ì„œ ê²°ê³¼ í™•ì¸ ë°©ë²• í•™ìŠµ\n",
    "\n",
    "### ğŸ“Š ì£¼ìš” í•™ìŠµ ë‚´ìš©\n",
    "- **Evaluation Dataset**: inputs, expectations, outputs êµ¬ì¡°\n",
    "- **Built-in Scorers**: LLM-as-Judge ë°©ì‹ì˜ ìë™ í‰ê°€\n",
    "- **mlflow.genai.evaluate()**: í‰ê°€ ì‹¤í–‰ API\n",
    "- **Feedback**: Scorerê°€ ë°˜í™˜í•˜ëŠ” í‰ê°€ ê²°ê³¼ (ê°’, ê·¼ê±°, ë©”íƒ€ë°ì´í„°)\n",
    "- **model_id**: ë²„ì „ ê´€ë¦¬ ë° ë¹„êµë¥¼ ìœ„í•œ ì‹ë³„ì\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Step 5)\n",
    "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ì»¤ìŠ¤í…€ RAG Scorers**ë¥¼ ë§Œë“¤ì–´:\n",
    "- RAG íŠ¹í™” ë©”íŠ¸ë¦­ ì •ì˜ (precision, recall, diversity)\n",
    "- Citation í’ˆì§ˆ í‰ê°€\n",
    "- Trace ê¸°ë°˜ í‰ê°€\n",
    "- í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì¤€ë¹„\n",
    "\n",
    "â†’ `05_mlflow_evaluation_custom_rag_scorers.ipynb`ë¡œ ê³„ì†í•˜ì„¸ìš”!\n",
    "\n",
    "### ğŸ’¡ Built-in Scorersì˜ ì¥ì \n",
    "1. **Zero-code í‰ê°€**: ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ì¦ëœ ë©”íŠ¸ë¦­\n",
    "2. **LLM-as-Judge**: ì‚¬ëŒì˜ íŒë‹¨ê³¼ ìœ ì‚¬í•œ í‰ê°€\n",
    "3. **ìë™í™”**: ëŒ€ê·œëª¨ í‰ê°€ ê°€ëŠ¥\n",
    "4. **ì¶”ì  ê°€ëŠ¥**: MLflowì— ëª¨ë“  ê²°ê³¼ ì €ì¥\n",
    "5. **ë¹„êµ ê°€ëŠ¥**: ì—¬ëŸ¬ ë²„ì „ ê°„ ê°ê´€ì  ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [MLflow GenAI Evaluation Guide](https://mlflow.org/docs/latest/genai/eval-monitor/)\n",
    "- [Built-in Scorers Documentation](https://mlflow.org/docs/latest/genai/concepts/scorers/)\n",
    "- [mlflow.genai.evaluate() API](https://mlflow.org/docs/latest/python_api/mlflow.genai.html#mlflow.genai.evaluate)\n",
    "- [Evaluation Quickstart](https://mlflow.org/docs/latest/genai/eval-monitor/quickstart/)\n",
    "- [LLM-as-Judge Best Practices](https://arxiv.org/abs/2306.05685)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-genai-tutorial (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
