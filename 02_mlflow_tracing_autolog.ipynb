{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Step 2: MLflow Tracing - ìë™ ì¶”ì  (Autolog)\n",
    "\n",
    "## ëª©í‘œ\n",
    "- LangChain Autolog í™œì„±í™”ë¡œ ì›ë¼ì¸ Tracing\n",
    "- Trace êµ¬ì¡° ì´í•´ (Span, Parent-Child ê´€ê³„)\n",
    "- Jupyter Notebookì—ì„œ Trace ì‹œê°í™”\n",
    "\n",
    "## í•™ìŠµ í¬ì¸íŠ¸\n",
    "- Autologì˜ í¸ë¦¬í•¨\n",
    "- Trace vs Runì˜ ì°¨ì´\n",
    "- Span êµ¬ì¡° (Parent-Child Hierarchy)\n",
    "- Token usage ìë™ ì¶”ì "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ì‚¬ì „ ì¤€ë¹„\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "ì´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê¸° ì „ì—:\n",
    "- **Step 0, 1** ì™„ë£Œ ê¶Œì¥\n",
    "- `.env` íŒŒì¼ ì„¤ì • ì™„ë£Œ\n",
    "- í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "\n",
    "### 1.1 í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n",
      "MLflow ë²„ì „: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from typing import TypedDict, List\n",
    "from datetime import datetime\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import Trace\n",
    "\n",
    "# LangChain & LangGraph\n",
    "from langchain_aws import ChatBedrock, BedrockEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "print(f\"MLflow ë²„ì „: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow Tracking ì„¤ì •\n",
    "\n",
    "### 2.1 Tracking URI ë° Experiment ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MLflow ì„¤ì • ì™„ë£Œ\n",
      "ğŸ“Š Experiment Name: rag_agent_tracing\n",
      "ğŸ†” Experiment ID: 899830758005961363\n"
     ]
    }
   ],
   "source": [
    "# Tracking URI ì„¤ì •\n",
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "\n",
    "# Experiment ì„¤ì •\n",
    "experiment_name = \"rag_agent_tracing\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "print(\"âœ… MLflow ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ğŸ“Š Experiment Name: {experiment.name}\")\n",
    "print(f\"ğŸ†” Experiment ID: {experiment.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LangChain Autolog í™œì„±í™”\n",
    "\n",
    "### 3.1 ê¸°ë³¸ Autolog\n",
    "\n",
    "**ë‹¨ í•œ ì¤„ì˜ ì½”ë“œë¡œ ìë™ ì¶”ì  í™œì„±í™”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangChain Autolog í™œì„±í™” ì™„ë£Œ\n",
      "ğŸ“ ì´ì œ LangChain/LangGraph í˜¸ì¶œì´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# LangChain ìë™ tracing í™œì„±í™”\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "print(\"âœ… LangChain Autolog í™œì„±í™” ì™„ë£Œ\")\n",
    "print(\"ğŸ“ ì´ì œ LangChain/LangGraph í˜¸ì¶œì´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ì„¸ë°€í•œ Autolog ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ë” ë§ì€ ì •ë³´ë¥¼ ë¡œê¹…í•˜ë ¤ë©´ ì¶”ê°€ ì˜µì…˜ í™œì„±í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¸ë°€í•œ Autolog ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë” ìƒì„¸í•œ ë¡œê¹… ì˜µì…˜ (ì„ íƒì )\n",
    "mlflow.langchain.autolog(\n",
    "    log_traces=True,                # Trace í™œì„±í™”\n",
    "    silent=False,                   # ê²½ê³  ë° ì´ë²¤íŠ¸ ë¡œê·¸ í‘œì‹œ\n",
    "    disable=False,                  # Autolog í™œì„±í™”\n",
    "    exclusive=False,                # ì‚¬ìš©ì ìƒì„± runì—ë„ ë¡œê¹…\n",
    ")\n",
    "\n",
    "print(\"âœ… ì„¸ë°€í•œ Autolog ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG Agent êµ¬ì„±\n",
    "\n",
    "Step 0, 1ê³¼ ë™ì¼í•œ RAG Agentë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ìƒ˜í”Œ ë¬¸ì„œ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 4ê°œì˜ ìƒ˜í”Œ ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "sample_documents = [\n",
    "    \"\"\"\n",
    "    RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Vector StoreëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\n",
    "    FAISS, Chroma, Pinecone ë“±ì´ ëŒ€í‘œì ì¸ Vector Storeì…ë‹ˆë‹¤.\n",
    "    Vector StoreëŠ” ìœ ì‚¬ë„ ê²€ìƒ‰(Similarity Search)ì„ í†µí•´ ì¿¼ë¦¬ì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ëƒ…ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
    "    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(sample_documents)}ê°œì˜ ìƒ˜í”Œ ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Vector Store ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector Store ìƒì„± ì™„ë£Œ (4ê°œ chunks)\n",
      "ğŸ“¦ ì„ë² ë”© ëª¨ë¸: amazon.titan-embed-text-v2:0\n"
     ]
    }
   ],
   "source": [
    "# AWS í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "AWS_MODEL_ID = os.getenv(\"AWS_MODEL_ID\")\n",
    "AWS_EMD_MODEL_ID = os.getenv(\"AWS_EMD_MODEL_ID\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "documents = [Document(page_content=doc.strip()) for doc in sample_documents]\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# ì„ë² ë”© ë° Vector Store ìƒì„± (AWS Bedrock)\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=AWS_EMD_MODEL_ID,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "print(f\"âœ… Vector Store ìƒì„± ì™„ë£Œ ({len(split_docs)}ê°œ chunks)\")\n",
    "print(f\"ğŸ“¦ ì„ë² ë”© ëª¨ë¸: {AWS_EMD_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 RAG Agent ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG Agent êµ¬ì„± ì™„ë£Œ\n",
      "ğŸ¤– LLM ëª¨ë¸: global.anthropic.claude-sonnet-4-5-20250929-v1:0\n"
     ]
    }
   ],
   "source": [
    "class RAGState(TypedDict):\n",
    "    \"\"\"RAG Agentì˜ ìƒíƒœ\"\"\"\n",
    "    query: str\n",
    "    retrieved_documents: List[Document]\n",
    "    context: str\n",
    "    answer: str\n",
    "    metadata: dict\n",
    "\n",
    "\n",
    "def retriever_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"query\"], k=3)\n",
    "    state[\"retrieved_documents\"] = retrieved_docs\n",
    "    state[\"metadata\"][\"num_retrieved_docs\"] = len(retrieved_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "def generator_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë‹µë³€ ìƒì„± ë…¸ë“œ\"\"\"\n",
    "    # Context ìƒì„±\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[ë¬¸ì„œ {i+1}]\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(state[\"retrieved_documents\"])\n",
    "    ])\n",
    "    state[\"context\"] = context\n",
    "    \n",
    "    # Prompt ìƒì„±\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"human\", \"ì»¨í…ìŠ¤íŠ¸:\\n{context}\\n\\nì§ˆë¬¸: {query}\\n\\në‹µë³€:\")\n",
    "    ])\n",
    "    \n",
    "    # LLM í˜¸ì¶œ (AWS Bedrock)\n",
    "    llm = ChatBedrock(\n",
    "        model_id=AWS_MODEL_ID,\n",
    "        region_name=AWS_REGION,\n",
    "        model_kwargs={\"temperature\": 0.7}\n",
    "    )\n",
    "    \n",
    "    messages = prompt_template.format_messages(context=context, query=state[\"query\"])\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    state[\"answer\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "# LangGraph êµ¬ì„±\n",
    "workflow = StateGraph(RAGState)\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"generator\", generator_node)\n",
    "workflow.add_edge(START, \"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"generator\")\n",
    "workflow.add_edge(\"generator\", END)\n",
    "\n",
    "rag_agent = workflow.compile()\n",
    "\n",
    "print(\"âœ… RAG Agent êµ¬ì„± ì™„ë£Œ\")\n",
    "print(f\"ğŸ¤– LLM ëª¨ë¸: {AWS_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Autologë¡œ ìë™ Tracing ì‹¤í–‰\n",
    "\n",
    "### 5.1 ì²« ë²ˆì§¸ ì‹¤í–‰ - ìë™ Trace ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ RAG Agent ì‹¤í–‰ (Autologë¡œ ìë™ Trace ìƒì„±)\n",
      "================================================================================\n",
      "\n",
      "âœ… ì‹¤í–‰ ì™„ë£Œ\n",
      "\n",
      "â“ ì§ˆë¬¸: MLflow Tracingì´ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ìë™ ê¸°ë¡**: ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ê³„ì¸µ êµ¬ì¡°**: TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì›Œí¬í”Œë¡œìš° ì‹œê°í™”**: Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ìƒì„¸ ì •ë³´**: ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ì‹¤í–‰ ê³¼ì •ì„ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ: 3ê°œ\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ Traceê°€ ìë™ìœ¼ë¡œ MLflowì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ RAG Agent ì‹¤í–‰ (Autologë¡œ ìë™ Trace ìƒì„±)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "test_query = \"MLflow Tracingì´ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# ì´ˆê¸° ìƒíƒœ\n",
    "initial_state = {\n",
    "    \"query\": test_query,\n",
    "    \"retrieved_documents\": [],\n",
    "    \"context\": \"\",\n",
    "    \"answer\": \"\",\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "# RAG Agent ì‹¤í–‰ (ìë™ìœ¼ë¡œ trace ìƒì„±ë¨!)\n",
    "result = rag_agent.invoke(initial_state)\n",
    "\n",
    "print(f\"\\nâœ… ì‹¤í–‰ ì™„ë£Œ\")\n",
    "print(f\"\\nâ“ ì§ˆë¬¸: {test_query}\")\n",
    "print(f\"\\nğŸ’¬ ë‹µë³€:\\n{result['answer']}\")\n",
    "print(f\"\\nğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(result['retrieved_documents'])}ê°œ\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ Traceê°€ ìë™ìœ¼ë¡œ MLflowì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ Trace ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”„ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ Trace ìƒì„±\n",
      "================================================================================\n",
      "\n",
      "[1/3] ì¿¼ë¦¬: RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "âœ… ì™„ë£Œ - ë‹µë³€ ê¸¸ì´: 281 ë¬¸ì\n",
      "\n",
      "[2/3] ì¿¼ë¦¬: Vector StoreëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?\n",
      "âœ… ì™„ë£Œ - ë‹µë³€ ê¸¸ì´: 496 ë¬¸ì\n",
      "\n",
      "[3/3] ì¿¼ë¦¬: Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "âœ… ì™„ë£Œ - ë‹µë³€ ê¸¸ì´: 458 ë¬¸ì\n",
      "\n",
      "================================================================================\n",
      "âœ… ì´ 3ê°œì˜ Trace ìƒì„± ì™„ë£Œ\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "test_queries = [\n",
    "    \"RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"Vector StoreëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?\",\n",
    "    \"Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”„ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ Trace ìƒì„±\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n[{i}/{len(test_queries)}] ì¿¼ë¦¬: {query}\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": [],\n",
    "        \"context\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"metadata\": {}\n",
    "    }\n",
    "    \n",
    "    result = rag_agent.invoke(initial_state)\n",
    "    print(f\"âœ… ì™„ë£Œ - ë‹µë³€ ê¸¸ì´: {len(result['answer'])} ë¬¸ì\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ì´ {len(test_queries)}ê°œì˜ Trace ìƒì„± ì™„ë£Œ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trace ê²€ìƒ‰ ë° ë¶„ì„\n",
    "\n",
    "### 6.1 ìµœê·¼ Trace ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ê²€ìƒ‰ëœ Trace: 8ê°œ\n",
      "\n",
      "================================================================================\n",
      "Request ID                               ì‹¤í–‰ ì‹œê°„           Spans     \n",
      "================================================================================\n",
      "tr-343aeaf764e899ccf61b7cd78524af78      5935ms          4         \n",
      "tr-2269058e15d2ef0e990ce0bdd221137e      5899ms          4         \n",
      "tr-310e991193d35a586bb5a21dbf0d4516      5139ms          4         \n",
      "tr-5ce4a10934a606eb5c749ce56d4a56cf      4236ms          4         \n",
      "tr-10c9234fb6358234747ffa42ec66e3f8      6244ms          4         \n",
      "tr-6f9c12f6277fb8e5939c2f1264473c3a      6346ms          4         \n",
      "tr-db01ed48e6e72ae8f27faf7e688e9159      5278ms          4         \n",
      "tr-c3535b12e726b0837905cc851b683661      4809ms          4         \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Trace ê²€ìƒ‰ (ìµœì‹  API ì‚¬ìš©)\n",
    "traces = mlflow.search_traces(\n",
    "    locations=[experiment.experiment_id],  # locations íŒŒë¼ë¯¸í„° ì‚¬ìš© (experiment_idsëŠ” deprecated)\n",
    "    max_results=10,\n",
    "    order_by=[\"timestamp_ms DESC\"],  # ìµœì‹ ìˆœ ì •ë ¬\n",
    "    return_type=\"list\"  # list íƒ€ì…ìœ¼ë¡œ ë°˜í™˜\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š ê²€ìƒ‰ëœ Trace: {len(traces)}ê°œ\\n\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Request ID':<40} {'ì‹¤í–‰ ì‹œê°„':<15} {'Spans':<10}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for trace in traces:\n",
    "    request_id = trace.info.request_id[:36]  # ì• 36ìë§Œ í‘œì‹œ\n",
    "    exec_time = f\"{trace.info.execution_time_ms:.0f}ms\" if trace.info.execution_time_ms else \"N/A\"\n",
    "    # spansëŠ” search_spans() ë©”ì„œë“œë¡œ ì ‘ê·¼\n",
    "    num_spans = len(trace.search_spans())\n",
    "    \n",
    "    print(f\"{request_id:<40} {exec_time:<15} {num_spans:<10}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 íŠ¹ì • Trace ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” ìµœê·¼ Trace ìƒì„¸ ì •ë³´\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ ê¸°ë³¸ ì •ë³´:\n",
      "  â€¢ Request ID: tr-343aeaf764e899ccf61b7cd78524af78\n",
      "  â€¢ Timestamp: 2025-12-16 11:40:58.867000\n",
      "  â€¢ ì‹¤í–‰ ì‹œê°„: 5935ms\n",
      "  â€¢ ìƒíƒœ: TraceStatus.OK\n",
      "\n",
      "ğŸ“Š Spans êµ¬ì¡°:\n",
      "â”œâ”€ [1] LangGraph\n",
      "    â€¢ Span ID: 886826f17bedcd23...\n",
      "    â€¢ ì‹œì‘: 1765852858867ms\n",
      "    â€¢ ì¢…ë£Œ: 1765852864802ms\n",
      "  â””â”€ [2] retriever\n",
      "      â€¢ Span ID: 515298ba9da38d9b...\n",
      "      â€¢ ì‹œì‘: 1765852858868ms\n",
      "      â€¢ ì¢…ë£Œ: 1765852858969ms\n",
      "      â€¢ Parent: 886826f17bedcd23...\n",
      "  â””â”€ [3] generator\n",
      "      â€¢ Span ID: 53e44f3d598f722b...\n",
      "      â€¢ ì‹œì‘: 1765852858970ms\n",
      "      â€¢ ì¢…ë£Œ: 1765852864801ms\n",
      "      â€¢ Parent: 886826f17bedcd23...\n",
      "  â””â”€ [4] ChatBedrock\n",
      "      â€¢ Span ID: b4150cf077b361c2...\n",
      "      â€¢ ì‹œì‘: 1765852859073ms\n",
      "      â€¢ ì¢…ë£Œ: 1765852864798ms\n",
      "      â€¢ Parent: 53e44f3d598f722b...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if traces:\n",
    "    # ê°€ì¥ ìµœê·¼ Trace ì„ íƒ\n",
    "    latest_trace = traces[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ” ìµœê·¼ Trace ìƒì„¸ ì •ë³´\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ê¸°ë³¸ ì •ë³´:\")\n",
    "    print(f\"  â€¢ Request ID: {latest_trace.info.request_id}\")\n",
    "    print(f\"  â€¢ Timestamp: {datetime.fromtimestamp(latest_trace.info.timestamp_ms/1000)}\")\n",
    "    print(f\"  â€¢ ì‹¤í–‰ ì‹œê°„: {latest_trace.info.execution_time_ms:.0f}ms\")\n",
    "    print(f\"  â€¢ ìƒíƒœ: {latest_trace.info.status}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Spans êµ¬ì¡°:\")\n",
    "    # search_spans() ë©”ì„œë“œë¡œ spans ê°€ì ¸ì˜¤ê¸°\n",
    "    spans = latest_trace.search_spans()\n",
    "    if spans:\n",
    "        for i, span in enumerate(spans, 1):\n",
    "            indent = \"  \" * (span.parent_id is not None)\n",
    "            span_type = \"â””â”€\" if span.parent_id else \"â”œâ”€\"\n",
    "            print(f\"{indent}{span_type} [{i}] {span.name}\")\n",
    "            print(f\"{indent}    â€¢ Span ID: {span.span_id[:16]}...\")\n",
    "            print(f\"{indent}    â€¢ ì‹œì‘: {span.start_time_ns // 1_000_000}ms\")\n",
    "            print(f\"{indent}    â€¢ ì¢…ë£Œ: {span.end_time_ns // 1_000_000}ms\")\n",
    "            if span.parent_id:\n",
    "                print(f\"{indent}    â€¢ Parent: {span.parent_id[:16]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(\"âš ï¸  ê²€ìƒ‰ëœ Traceê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Trace ì…ì¶œë ¥ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“¥ğŸ“¤ Trace ì…ì¶œë ¥ ì •ë³´\n",
      "================================================================================\n",
      "\n",
      "[1] LangGraph\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“¥ Inputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [], 'context': '', 'answer': '', 'metadata': {}}...\n",
      "\n",
      "ğŸ“¤ Outputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spa...\n",
      "\n",
      "ğŸ·ï¸  Attributes:\n",
      "  â€¢ mlflow.traceRequestId: tr-343aeaf764e899ccf61b7cd78524af78\n",
      "  â€¢ mlflow.spanType: CHAIN\n",
      "  â€¢ mlflow.spanInputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [], 'context': '', 'answer': '', 'metadata': {}}\n",
      "  â€¢ mlflow.spanOutputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '37c3f590-cc12-4707-9ada-56803e006b97', 'metadata': {}, 'page_content': 'MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '80afb039-8119-4e88-a21a-073ddf504adf', 'metadata': {}, 'page_content': 'RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'type': 'Document'}], 'context': '[ë¬¸ì„œ 1]\\nSpanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 2]\\nMLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 3]\\nRAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'answer': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤:\\n\\n## ê¸°ë³¸ ê°œë…\\n- **Span**ì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n- **Parent Span**ê³¼ **Child Span**ì˜ ê³„ì¸µì  ê´€ê³„ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n## ê³„ì¸µ êµ¬ì¡°ì˜ íŠ¹ì§•\\n1. **ìƒìœ„-í•˜ìœ„ ê´€ê³„**: Parent Span ì•„ë˜ì— ì—¬ëŸ¬ Child Spanì´ ì¡´ì¬í•  ìˆ˜ ìˆì–´, ì‘ì—…ì˜ ì„¸ë¶€ ë‹¨ê³„ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.\\n\\n2. **ê° Spanì˜ êµ¬ì„± ìš”ì†Œ**:\\n   - ì‹œì‘ ì‹œê°„\\n   - ì¢…ë£Œ ì‹œê°„\\n   - ì…ë ¥\\n   - ì¶œë ¥\\n   - ë©”íƒ€ë°ì´í„°\\n\\n3. **Traceì™€ì˜ ê´€ê³„**: TraceëŠ” ì´ëŸ¬í•œ Spanë“¤ì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì²´ ì‹¤í–‰ ê³¼ì •ì„ ì¶”ì í•©ë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê° ë‹¨ê³„ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', 'metadata': {'num_retrieved_docs': 3}}\n",
      "\n",
      "[2] retriever\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“¥ Inputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [], 'context': '', 'answer': '', 'metadata': {}}...\n",
      "\n",
      "ğŸ“¤ Outputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spa...\n",
      "\n",
      "ğŸ·ï¸  Attributes:\n",
      "  â€¢ mlflow.traceRequestId: tr-343aeaf764e899ccf61b7cd78524af78\n",
      "  â€¢ mlflow.spanType: CHAIN\n",
      "  â€¢ mlflow.spanInputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [], 'context': '', 'answer': '', 'metadata': {}}\n",
      "  â€¢ metadata: {'langgraph_step': 1, 'langgraph_node': 'retriever', 'langgraph_triggers': ['branch:to:retriever'], 'langgraph_path': ['__pregel_pull', 'retriever'], 'langgraph_checkpoint_ns': 'retriever:fde9ae61-4b73-ebfa-7c78-f22720f337bb'}\n",
      "  â€¢ mlflow.spanOutputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '37c3f590-cc12-4707-9ada-56803e006b97', 'metadata': {}, 'page_content': 'MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '80afb039-8119-4e88-a21a-073ddf504adf', 'metadata': {}, 'page_content': 'RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'type': 'Document'}], 'context': '', 'answer': '', 'metadata': {'num_retrieved_docs': 3}}\n",
      "\n",
      "[3] generator\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“¥ Inputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spa...\n",
      "\n",
      "ğŸ“¤ Outputs:\n",
      "  {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spa...\n",
      "\n",
      "ğŸ·ï¸  Attributes:\n",
      "  â€¢ mlflow.traceRequestId: tr-343aeaf764e899ccf61b7cd78524af78\n",
      "  â€¢ mlflow.spanType: CHAIN\n",
      "  â€¢ mlflow.spanInputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '37c3f590-cc12-4707-9ada-56803e006b97', 'metadata': {}, 'page_content': 'MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '80afb039-8119-4e88-a21a-073ddf504adf', 'metadata': {}, 'page_content': 'RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'type': 'Document'}], 'context': '', 'answer': '', 'metadata': {'num_retrieved_docs': 3}}\n",
      "  â€¢ metadata: {'langgraph_step': 2, 'langgraph_node': 'generator', 'langgraph_triggers': ['branch:to:generator'], 'langgraph_path': ['__pregel_pull', 'generator'], 'langgraph_checkpoint_ns': 'generator:b5743d6c-f230-91ce-6e24-5781c6917170'}\n",
      "  â€¢ mlflow.spanOutputs: {'query': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'retrieved_documents': [{'id': '6f8ba009-c207-4cdb-ae06-9adb705eb76d', 'metadata': {}, 'page_content': 'Spanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '37c3f590-cc12-4707-9ada-56803e006b97', 'metadata': {}, 'page_content': 'MLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.', 'type': 'Document'}, {'id': '80afb039-8119-4e88-a21a-073ddf504adf', 'metadata': {}, 'page_content': 'RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'type': 'Document'}], 'context': '[ë¬¸ì„œ 1]\\nSpanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 2]\\nMLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 3]\\nRAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.', 'answer': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤:\\n\\n## ê¸°ë³¸ ê°œë…\\n- **Span**ì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n- **Parent Span**ê³¼ **Child Span**ì˜ ê³„ì¸µì  ê´€ê³„ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n## ê³„ì¸µ êµ¬ì¡°ì˜ íŠ¹ì§•\\n1. **ìƒìœ„-í•˜ìœ„ ê´€ê³„**: Parent Span ì•„ë˜ì— ì—¬ëŸ¬ Child Spanì´ ì¡´ì¬í•  ìˆ˜ ìˆì–´, ì‘ì—…ì˜ ì„¸ë¶€ ë‹¨ê³„ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.\\n\\n2. **ê° Spanì˜ êµ¬ì„± ìš”ì†Œ**:\\n   - ì‹œì‘ ì‹œê°„\\n   - ì¢…ë£Œ ì‹œê°„\\n   - ì…ë ¥\\n   - ì¶œë ¥\\n   - ë©”íƒ€ë°ì´í„°\\n\\n3. **Traceì™€ì˜ ê´€ê³„**: TraceëŠ” ì´ëŸ¬í•œ Spanë“¤ì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì²´ ì‹¤í–‰ ê³¼ì •ì„ ì¶”ì í•©ë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê° ë‹¨ê³„ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', 'metadata': {'num_retrieved_docs': 3}}\n",
      "\n",
      "[4] ChatBedrock\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“¥ Inputs:\n",
      "  [[{'content': 'ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'system', 'name': None, 'id': None}, {'content': 'ì»¨í…ìŠ¤íŠ¸:\\n[ë¬¸ì„œ...\n",
      "\n",
      "ğŸ“¤ Outputs:\n",
      "  {'generations': [[{'text': 'Spanì˜ ê³„ì¸µ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤:\\n\\n## ê¸°ë³¸ ê°œë…\\n- **Span**ì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n- **Parent Span**ê³¼ **Child Span**ì˜ ê³„ì¸µì  ê´€ê³„ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n## ê³„ì¸µ êµ¬ì¡°...\n",
      "\n",
      "ğŸ·ï¸  Attributes:\n",
      "  â€¢ mlflow.traceRequestId: tr-343aeaf764e899ccf61b7cd78524af78\n",
      "  â€¢ mlflow.spanType: CHAT_MODEL\n",
      "  â€¢ mlflow.spanInputs: [[{'content': 'ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'system', 'name': None, 'id': None}, {'content': 'ì»¨í…ìŠ¤íŠ¸:\\n[ë¬¸ì„œ 1]\\nSpanì€ Traceì˜ êµ¬ì„± ìš”ì†Œë¡œ, ë‹¨ì¼ ì‘ì—… ë˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n    Parent Spanê³¼ Child Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    ê° Spanì€ ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„, ì…ë ¥, ì¶œë ¥, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 2]\\nMLflow Tracingì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\\n    ê° ë‹¨ê³„ì˜ ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\\n    TraceëŠ” Spanì˜ ê³„ì¸µ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ë©°, ê° Spanì€ íŠ¹ì • ì‘ì—…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\\n\\n[ë¬¸ì„œ 3]\\nRAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\\n    RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n    ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\\n\\nì§ˆë¬¸: Spanì˜ ê³„ì¸µ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\\n\\në‹µë³€:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}]]\n",
      "  â€¢ invocation_params: {'model_id': 'global.anthropic.claude-sonnet-4-5-20250929-v1:0', 'base_model_id': None, 'provider': 'anthropic', 'stream': False, 'trace': None, 'guardrailIdentifier': None, 'guardrailVersion': None, '_type': 'amazon_bedrock_chat', 'stop': None}\n",
      "  â€¢ options: {'stop': None}\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if traces:\n",
    "    latest_trace = traces[0]\n",
    "    spans = latest_trace.search_spans()\n",
    "    \n",
    "    if spans:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ“¥ğŸ“¤ Trace ì…ì¶œë ¥ ì •ë³´\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, span in enumerate(spans, 1):\n",
    "            print(f\"\\n[{i}] {span.name}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # Inputs\n",
    "            if span.inputs:\n",
    "                print(f\"ğŸ“¥ Inputs:\")\n",
    "                inputs_str = str(span.inputs)[:200]  # ì²˜ìŒ 200ìë§Œ\n",
    "                print(f\"  {inputs_str}...\")\n",
    "            \n",
    "            # Outputs\n",
    "            if span.outputs:\n",
    "                print(f\"\\nğŸ“¤ Outputs:\")\n",
    "                outputs_str = str(span.outputs)[:200]  # ì²˜ìŒ 200ìë§Œ\n",
    "                print(f\"  {outputs_str}...\")\n",
    "            \n",
    "            # Attributes (ë©”íƒ€ë°ì´í„°)\n",
    "            if span.attributes:\n",
    "                print(f\"\\nğŸ·ï¸  Attributes:\")\n",
    "                for key, value in list(span.attributes.items())[:5]:  # ì²˜ìŒ 5ê°œë§Œ\n",
    "                    print(f\"  â€¢ {key}: {value}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Span ê³„ì¸µ êµ¬ì¡° ì‹œê°í™”\n",
    "\n",
    "### 7.1 Traceì˜ Span ê³„ì¸µ êµ¬ì¡° íŠ¸ë¦¬ë¡œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Span ê³„ì¸µ êµ¬ì¡°\n",
      "================================================================================\n",
      "\n",
      "ğŸŒ³ LangGraph (5935.31ms)\n",
      "   ğŸ“‹ Type: CHAIN\n",
      "  â””â”€ retriever (101.47ms)\n",
      "     ğŸ“‹ Type: CHAIN\n",
      "  â””â”€ generator (5831.78ms)\n",
      "     ğŸ“‹ Type: CHAIN\n",
      "    â””â”€ ChatBedrock (5724.35ms)\n",
      "       ğŸ“‹ Type: CHAT_MODEL\n",
      "\n",
      "ğŸ’° ì „ì²´ Token Usage:\n",
      "   â€¢ Input Tokens: 555\n",
      "   â€¢ Output Tokens: 380\n",
      "   â€¢ Total Tokens: 935\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_span_tree(trace, indent=0):\n",
    "    \"\"\"\n",
    "    Traceì˜ Span ê³„ì¸µ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    # search_spans() ë©”ì„œë“œë¡œ spans ê°€ì ¸ì˜¤ê¸°\n",
    "    spans = trace.search_spans()\n",
    "    \n",
    "    if not spans:\n",
    "        print(\"Spanì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # Parent-Child ê´€ê³„ êµ¬ì¶•\n",
    "    span_map = {span.span_id: span for span in spans}\n",
    "    root_spans = [span for span in spans if span.parent_id is None]\n",
    "    \n",
    "    def print_span_recursive(span, level=0):\n",
    "        prefix = \"  \" * level\n",
    "        symbol = \"â””â”€\" if level > 0 else \"ğŸŒ³\"\n",
    "        \n",
    "        # Span ì •ë³´ ì¶œë ¥\n",
    "        duration_ms = (span.end_time_ns - span.start_time_ns) / 1_000_000\n",
    "        print(f\"{prefix}{symbol} {span.name} ({duration_ms:.2f}ms)\")\n",
    "        \n",
    "        # Span type í‘œì‹œ\n",
    "        if span.span_type:\n",
    "            print(f\"{prefix}   ğŸ“‹ Type: {span.span_type}\")\n",
    "        \n",
    "        # Child Spans ì¬ê·€ ì¶œë ¥\n",
    "        children = [s for s in spans if s.parent_id == span.span_id]\n",
    "        for child in children:\n",
    "            print_span_recursive(child, level + 1)\n",
    "    \n",
    "    # Root Spansë¶€í„° ì¶œë ¥\n",
    "    for root_span in root_spans:\n",
    "        print_span_recursive(root_span)\n",
    "    \n",
    "    # Trace ì „ì²´ì˜ Token usage í‘œì‹œ (trace.info.token_usage ì‚¬ìš©)\n",
    "    token_usage = trace.info.token_usage\n",
    "    if token_usage:\n",
    "        print(f\"\\nğŸ’° ì „ì²´ Token Usage:\")\n",
    "        print(f\"   â€¢ Input Tokens: {token_usage.get('input_tokens', 0)}\")\n",
    "        print(f\"   â€¢ Output Tokens: {token_usage.get('output_tokens', 0)}\")\n",
    "        print(f\"   â€¢ Total Tokens: {token_usage.get('total_tokens', 0)}\")\n",
    "\n",
    "\n",
    "if traces:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸŒ³ Span ê³„ì¸µ êµ¬ì¡°\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print_span_tree(traces[0])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Token Usage ìë™ ì¶”ì \n",
    "\n",
    "AutologëŠ” LLM í˜¸ì¶œ ì‹œ Token usageë¥¼ ìë™ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "**MLflow 3.xì˜ Token Usage êµ¬ì¡°:**\n",
    "- Token ì •ë³´ëŠ” `trace.info.token_usage` ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤\n",
    "- í‚¤: `input_tokens`, `output_tokens`, `total_tokens`\n",
    "- Span ë ˆë²¨ì´ ì•„ë‹Œ Trace ë ˆë²¨ì—ì„œ ì§‘ê³„ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Token Usage ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ’° Token Usage ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "[1] Trace tr-343aeaf764e89...\n",
      "  â€¢ Total Tokens: 935\n",
      "  â€¢ Input Tokens: 555\n",
      "  â€¢ Output Tokens: 380\n",
      "\n",
      "[2] Trace tr-2269058e15d2e...\n",
      "  â€¢ Total Tokens: 908\n",
      "  â€¢ Input Tokens: 507\n",
      "  â€¢ Output Tokens: 401\n",
      "\n",
      "[3] Trace tr-310e991193d35...\n",
      "  â€¢ Total Tokens: 801\n",
      "  â€¢ Input Tokens: 545\n",
      "  â€¢ Output Tokens: 256\n",
      "\n",
      "[4] Trace tr-5ce4a10934a60...\n",
      "  â€¢ Total Tokens: 849\n",
      "  â€¢ Input Tokens: 548\n",
      "  â€¢ Output Tokens: 301\n",
      "\n",
      "[5] Trace tr-10c9234fb6358...\n",
      "  â€¢ Total Tokens: 922\n",
      "  â€¢ Input Tokens: 555\n",
      "  â€¢ Output Tokens: 367\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ì´ Token ì‚¬ìš©ëŸ‰: 4415 tokens\n",
      "   - Input Tokens: 2710\n",
      "   - Output Tokens: 1705\n",
      "ğŸ’µ ì˜ˆìƒ ë¹„ìš©: $0.033705\n",
      "   - Input: $0.008130 (2710 tokens)\n",
      "   - Output: $0.025575 (1705 tokens)\n",
      "   - ëª¨ë¸: Claude Sonnet 4.5 (Bedrock)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def extract_token_usage(trace):\n",
    "    \"\"\"\n",
    "    Traceì—ì„œ Token usage ì •ë³´ ì¶”ì¶œ\n",
    "    \n",
    "    MLflow 3.xì—ì„œëŠ” token usageê°€ trace.info.token_usageì— ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "    í‚¤: 'input_tokens', 'output_tokens', 'total_tokens'\n",
    "    \"\"\"\n",
    "    # trace.info.token_usageì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n",
    "    token_usage = trace.info.token_usage or {}\n",
    "    \n",
    "    return {\n",
    "        'total_tokens': token_usage.get('total_tokens', 0),\n",
    "        'prompt_tokens': token_usage.get('input_tokens', 0),  # input_tokensê°€ prompt_tokensì™€ ë™ì¼\n",
    "        'completion_tokens': token_usage.get('output_tokens', 0)  # output_tokensê°€ completion_tokensì™€ ë™ì¼\n",
    "    }\n",
    "\n",
    "\n",
    "if traces:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ’° Token Usage ë¶„ì„\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    total_all = 0\n",
    "    total_prompt = 0\n",
    "    total_completion = 0\n",
    "    \n",
    "    for i, trace in enumerate(traces[:5], 1):  # ìµœê·¼ 5ê°œ\n",
    "        usage = extract_token_usage(trace)\n",
    "        total_all += usage['total_tokens']\n",
    "        total_prompt += usage['prompt_tokens']\n",
    "        total_completion += usage['completion_tokens']\n",
    "        \n",
    "        print(f\"[{i}] Trace {trace.info.request_id[:16]}...\")\n",
    "        print(f\"  â€¢ Total Tokens: {usage['total_tokens']}\")\n",
    "        print(f\"  â€¢ Input Tokens: {usage['prompt_tokens']}\")\n",
    "        print(f\"  â€¢ Output Tokens: {usage['completion_tokens']}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“Š ì´ Token ì‚¬ìš©ëŸ‰: {total_all} tokens\")\n",
    "    print(f\"   - Input Tokens: {total_prompt}\")\n",
    "    print(f\"   - Output Tokens: {total_completion}\")\n",
    "    \n",
    "    # ë¹„ìš© ì¶”ì • (AWS Bedrock Claude Sonnet 4.5 ê¸°ì¤€)\n",
    "    # ê°€ê²©ì€ ë¦¬ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (us-east-1 ê¸°ì¤€)\n",
    "    input_cost_per_1k = 0.003   # $3 per 1M tokens = $0.003 per 1K\n",
    "    output_cost_per_1k = 0.015  # $15 per 1M tokens = $0.015 per 1K\n",
    "    \n",
    "    input_cost = (total_prompt / 1000) * input_cost_per_1k\n",
    "    output_cost = (total_completion / 1000) * output_cost_per_1k\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"ğŸ’µ ì˜ˆìƒ ë¹„ìš©: ${total_cost:.6f}\")\n",
    "    print(f\"   - Input: ${input_cost:.6f} ({total_prompt} tokens)\")\n",
    "    print(f\"   - Output: ${output_cost:.6f} ({total_completion} tokens)\")\n",
    "    print(f\"   - ëª¨ë¸: Claude Sonnet 4.5 (Bedrock)\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Trace vs Run ë¹„êµ\n",
    "\n",
    "### 9.1 ê°œë… ì°¨ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“š Trace vs Run ë¹„êµ\n",
      "================================================================================\n",
      "íŠ¹ì§•                   | Trace                               | Run                                \n",
      "-------------------- | ----------------------------------- | -----------------------------------\n",
      "ëª©ì                    | ì‹¤í–‰ ê³¼ì •ì˜ ìƒì„¸ ì¶”ì                         | ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡                           \n",
      "ë‹¨ìœ„                   | ë‹¨ì¼ ìš”ì²­/í˜¸ì¶œ                            | ì „ì²´ ì‹¤í—˜                              \n",
      "êµ¬ì¡°                   | Spanì˜ ê³„ì¸µ êµ¬ì¡° (DAG)                   | í‰ë©´ êµ¬ì¡° (params + metrics)           \n",
      "ìë™í™”                  | Autologë¡œ ìë™ ìƒì„±                      | ìˆ˜ë™ ë¡œê¹… í•„ìš”                           \n",
      "ìƒì„¸ë„                  | ê° ë‹¨ê³„ë³„ ì…ì¶œë ¥ ê¸°ë¡                        | ì „ì²´ ìš”ì•½ ë©”íŠ¸ë¦­ë§Œ                         \n",
      "Token ì¶”ì              | ìë™ ì¶”ì                                | ìˆ˜ë™ ë¡œê¹… í•„ìš”                           \n",
      "ë””ë²„ê¹…                  | ë§¤ìš° ìœ ìš© (ë‹¨ê³„ë³„ í™•ì¸)                      | ì œí•œì  (ì „ì²´ ê²°ê³¼ë§Œ)                       \n",
      "ìš©ë„                   | í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§, ë””ë²„ê¹…                      | ì‹¤í—˜ ë¹„êµ, ëª¨ë¸ ì„ íƒ                       \n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ ê²°ë¡ : Traceì™€ Runì€ ìƒí˜¸ ë³´ì™„ì !\n",
      "  â€¢ Trace: ê° ìš”ì²­ì˜ ì‹¤í–‰ ê³¼ì • ì¶”ì  (ë””ë²„ê¹…, ëª¨ë‹ˆí„°ë§)\n",
      "  â€¢ Run: ì‹¤í—˜ ì„¤ì • ë° ê²°ê³¼ ë¹„êµ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“š Trace vs Run ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = [\n",
    "    [\"íŠ¹ì§•\", \"Trace\", \"Run\"],\n",
    "    [\"-\" * 20, \"-\" * 35, \"-\" * 35],\n",
    "    [\"ëª©ì \", \"ì‹¤í–‰ ê³¼ì •ì˜ ìƒì„¸ ì¶”ì \", \"ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡\"],\n",
    "    [\"ë‹¨ìœ„\", \"ë‹¨ì¼ ìš”ì²­/í˜¸ì¶œ\", \"ì „ì²´ ì‹¤í—˜\"],\n",
    "    [\"êµ¬ì¡°\", \"Spanì˜ ê³„ì¸µ êµ¬ì¡° (DAG)\", \"í‰ë©´ êµ¬ì¡° (params + metrics)\"],\n",
    "    [\"ìë™í™”\", \"Autologë¡œ ìë™ ìƒì„±\", \"ìˆ˜ë™ ë¡œê¹… í•„ìš”\"],\n",
    "    [\"ìƒì„¸ë„\", \"ê° ë‹¨ê³„ë³„ ì…ì¶œë ¥ ê¸°ë¡\", \"ì „ì²´ ìš”ì•½ ë©”íŠ¸ë¦­ë§Œ\"],\n",
    "    [\"Token ì¶”ì \", \"ìë™ ì¶”ì \", \"ìˆ˜ë™ ë¡œê¹… í•„ìš”\"],\n",
    "    [\"ë””ë²„ê¹…\", \"ë§¤ìš° ìœ ìš© (ë‹¨ê³„ë³„ í™•ì¸)\", \"ì œí•œì  (ì „ì²´ ê²°ê³¼ë§Œ)\"],\n",
    "    [\"ìš©ë„\", \"í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§, ë””ë²„ê¹…\", \"ì‹¤í—˜ ë¹„êµ, ëª¨ë¸ ì„ íƒ\"],\n",
    "]\n",
    "\n",
    "for row in comparison:\n",
    "    print(f\"{row[0]:<20} | {row[1]:<35} | {row[2]:<35}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ ê²°ë¡ : Traceì™€ Runì€ ìƒí˜¸ ë³´ì™„ì !\")\n",
    "print(\"  â€¢ Trace: ê° ìš”ì²­ì˜ ì‹¤í–‰ ê³¼ì • ì¶”ì  (ë””ë²„ê¹…, ëª¨ë‹ˆí„°ë§)\")\n",
    "print(\"  â€¢ Run: ì‹¤í—˜ ì„¤ì • ë° ê²°ê³¼ ë¹„êµ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. MLflow UIì—ì„œ Trace í™•ì¸\n",
    "\n",
    "### 10.1 UI ì‹¤í–‰ ë° íƒìƒ‰ ê°€ì´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸŒ MLflow UIì—ì„œ Trace í™•ì¸í•˜ê¸°\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ í„°ë¯¸ë„ì—ì„œ MLflow UI ì‹¤í–‰:\n",
      "   $ mlflow ui --port 5000\n",
      "\n",
      "2ï¸âƒ£ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:\n",
      "   http://localhost:5000\n",
      "\n",
      "3ï¸âƒ£ Experiment ì„ íƒ:\n",
      "   â€¢ 'rag_agent_tracing' ì‹¤í—˜ í´ë¦­\n",
      "\n",
      "4ï¸âƒ£ Traces íƒ­ ì´ë™:\n",
      "   â€¢ ìƒë‹¨ ë©”ë‰´ì—ì„œ 'Traces' íƒ­ í´ë¦­\n",
      "\n",
      "5ï¸âƒ£ ê°œë³„ Trace í™•ì¸:\n",
      "   â€¢ Request ID í´ë¦­\n",
      "   â€¢ Span ê³„ì¸µ êµ¬ì¡° ì‹œê°í™” í™•ì¸\n",
      "   â€¢ ê° Spanì˜ ì…ì¶œë ¥ í™•ì¸\n",
      "   â€¢ Token usage í™•ì¸\n",
      "   â€¢ ì‹¤í–‰ ì‹œê°„ Waterfall ì°¨íŠ¸ í™•ì¸\n",
      "\n",
      "6ï¸âƒ£ Trace í•„í„°ë§:\n",
      "   â€¢ ì‹¤í–‰ ì‹œê°„ìœ¼ë¡œ í•„í„°ë§\n",
      "   â€¢ ìƒíƒœë¡œ í•„í„°ë§ (ì„±ê³µ/ì‹¤íŒ¨)\n",
      "   â€¢ ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸŒ MLflow UIì—ì„œ Trace í™•ì¸í•˜ê¸°\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1ï¸âƒ£ í„°ë¯¸ë„ì—ì„œ MLflow UI ì‹¤í–‰:\n",
    "   $ mlflow ui --port 5000\n",
    "\n",
    "2ï¸âƒ£ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:\n",
    "   http://localhost:5000\n",
    "\n",
    "3ï¸âƒ£ Experiment ì„ íƒ:\n",
    "   â€¢ 'rag_agent_tracing' ì‹¤í—˜ í´ë¦­\n",
    "\n",
    "4ï¸âƒ£ Traces íƒ­ ì´ë™:\n",
    "   â€¢ ìƒë‹¨ ë©”ë‰´ì—ì„œ 'Traces' íƒ­ í´ë¦­\n",
    "\n",
    "5ï¸âƒ£ ê°œë³„ Trace í™•ì¸:\n",
    "   â€¢ Request ID í´ë¦­\n",
    "   â€¢ Span ê³„ì¸µ êµ¬ì¡° ì‹œê°í™” í™•ì¸\n",
    "   â€¢ ê° Spanì˜ ì…ì¶œë ¥ í™•ì¸\n",
    "   â€¢ Token usage í™•ì¸\n",
    "   â€¢ ì‹¤í–‰ ì‹œê°„ Waterfall ì°¨íŠ¸ í™•ì¸\n",
    "\n",
    "6ï¸âƒ£ Trace í•„í„°ë§:\n",
    "   â€¢ ì‹¤í–‰ ì‹œê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "   â€¢ ìƒíƒœë¡œ í•„í„°ë§ (ì„±ê³µ/ì‹¤íŒ¨)\n",
    "   â€¢ ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Jupyterì—ì„œ Trace ì‹œê°í™” (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trace JSON ë°ì´í„° (ìµœê·¼ Trace)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "execution_time_ms": 5935,
       "num_spans": 4,
       "request_id": "tr-343aeaf764e899ccf61b7cd78524af78",
       "spans": [
        {
         "duration_ms": 5935.309,
         "has_parent": false,
         "name": "LangGraph"
        },
        {
         "duration_ms": 101.475,
         "has_parent": true,
         "name": "retriever"
        },
        {
         "duration_ms": 5831.785,
         "has_parent": true,
         "name": "generator"
        },
        {
         "duration_ms": 5724.347,
         "has_parent": true,
         "name": "ChatBedrock"
        }
       ],
       "status": "OK",
       "timestamp": "2025-12-16 11:40:58.867000"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter Notebookì—ì„œ Trace ì •ë³´ ê°„ë‹¨íˆ í‘œì‹œ\n",
    "if traces:\n",
    "    from IPython.display import JSON, display\n",
    "    \n",
    "    print(\"\\nğŸ“Š Trace JSON ë°ì´í„° (ìµœê·¼ Trace)\\n\")\n",
    "    \n",
    "    latest_trace = traces[0]\n",
    "    spans = latest_trace.search_spans()\n",
    "    \n",
    "    # Traceë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "    trace_dict = {\n",
    "        \"request_id\": latest_trace.info.request_id,\n",
    "        \"timestamp\": str(datetime.fromtimestamp(latest_trace.info.timestamp_ms/1000)),\n",
    "        \"execution_time_ms\": latest_trace.info.execution_time_ms,\n",
    "        \"status\": latest_trace.info.status,\n",
    "        \"num_spans\": len(spans),\n",
    "        \"spans\": [\n",
    "            {\n",
    "                \"name\": span.name,\n",
    "                \"duration_ms\": (span.end_time_ns - span.start_time_ns) / 1_000_000,\n",
    "                \"has_parent\": span.parent_id is not None\n",
    "            }\n",
    "            for span in spans\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # JSON í˜•íƒœë¡œ í‘œì‹œ\n",
    "    display(JSON(trace_dict, expanded=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ê³ ê¸‰: Trace í•„í„°ë§ ë° ê²€ìƒ‰\n",
    "\n",
    "### 11.1 ì¡°ê±´ë³„ Trace ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ ëŠë¦° Trace (5ê°œ):\n",
      "  â€¢ tr-343aeaf764e89... - 5935ms\n",
      "  â€¢ tr-2269058e15d2e... - 5899ms\n",
      "  â€¢ tr-310e991193d35... - 5139ms\n",
      "  â€¢ tr-5ce4a10934a60... - 4236ms\n",
      "  â€¢ tr-10c9234fb6358... - 6244ms\n",
      "\n",
      "ğŸ• ìµœê·¼ 1ì‹œê°„ Trace (4ê°œ)\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ ì‹œê°„ì´ ê¸´ Trace ì°¾ê¸°\n",
    "slow_traces = mlflow.search_traces(\n",
    "    locations=[experiment.experiment_id],  # locations íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
    "    filter_string=\"execution_time_ms > 2000\",  # 2ì´ˆ ì´ìƒ\n",
    "    max_results=5,\n",
    "    return_type=\"list\"\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸŒ ëŠë¦° Trace ({len(slow_traces)}ê°œ):\")\n",
    "for trace in slow_traces:\n",
    "    print(f\"  â€¢ {trace.info.request_id[:16]}... - {trace.info.execution_time_ms:.0f}ms\")\n",
    "\n",
    "\n",
    "# ìµœê·¼ 1ì‹œê°„ ë‚´ Trace\n",
    "import time\n",
    "one_hour_ago = int((time.time() - 3600) * 1000)  # milliseconds\n",
    "\n",
    "recent_traces = mlflow.search_traces(\n",
    "    locations=[experiment.experiment_id],  # locations íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
    "    filter_string=f\"timestamp_ms > {one_hour_ago}\",\n",
    "    max_results=10,\n",
    "    return_type=\"list\"\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ• ìµœê·¼ 1ì‹œê°„ Trace ({len(recent_traces)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œí•œ ì‘ì—…\n",
    "1. LangChain Autolog í™œì„±í™” (ë‹¨ í•œ ì¤„!)\n",
    "2. RAG Agent ì‹¤í–‰ìœ¼ë¡œ ìë™ Trace ìƒì„±\n",
    "3. Trace êµ¬ì¡° ì´í•´ (Span ê³„ì¸µ)\n",
    "4. Token usage ìë™ ì¶”ì \n",
    "5. Trace ê²€ìƒ‰ ë° ë¶„ì„\n",
    "6. Trace vs Run ê°œë… ë¹„êµ\n",
    "\n",
    "### ğŸ“Š ì£¼ìš” í•™ìŠµ ë‚´ìš©\n",
    "- **Autolog**: ì½”ë“œ ìˆ˜ì • ì—†ì´ ìë™ ì¶”ì \n",
    "- **Trace**: ë‹¨ì¼ ìš”ì²­ì˜ ì „ì²´ ì‹¤í–‰ ê³¼ì •\n",
    "- **Span**: Traceë¥¼ êµ¬ì„±í•˜ëŠ” ê°œë³„ ì‘ì—… ë‹¨ìœ„\n",
    "- **ê³„ì¸µ êµ¬ì¡°**: Parent-Child ê´€ê³„ë¡œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì‹œê°í™”\n",
    "- **ìë™ ë©”íŠ¸ë¦­**: Token usage, ì‹¤í–‰ ì‹œê°„ ë“± ìë™ ìˆ˜ì§‘\n",
    "- **Token Usage**: `trace.info.token_usage`ì—ì„œ input/output/total tokens í™•ì¸\n",
    "\n",
    "### ğŸ”§ MLflow 3.x API ì£¼ìš” ë³€ê²½ì‚¬í•­\n",
    "- `experiment_ids` â†’ `locations` íŒŒë¼ë¯¸í„°ë¡œ ë³€ê²½\n",
    "- `return_type=\"list\"` ëª…ì‹œ í•„ìš”\n",
    "- Spans ì ‘ê·¼: `trace.data.spans` â†’ `trace.search_spans()` ë©”ì„œë“œ\n",
    "- Token usage: Span attributes ëŒ€ì‹  `trace.info.token_usage` ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Step 3)\n",
    "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ìˆ˜ë™ ì»¤ìŠ¤í…€ Span**ì„ í™œìš©í•˜ì—¬:\n",
    "- RAG íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ë¥¼ ì„¸ë°€í•˜ê²Œ ì¶”ì \n",
    "- ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "- ì„±ëŠ¥ ë³‘ëª© ì§€ì  ì‹ë³„\n",
    "- í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì¤€ë¹„\n",
    "\n",
    "â†’ `03_mlflow_tracing_custom_spans.ipynb`ë¡œ ê³„ì†í•˜ì„¸ìš”!\n",
    "\n",
    "### ğŸ’¡ Autologì˜ ì¥ì \n",
    "1. **Zero-code ì¶”ì **: ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ìŒ\n",
    "2. **ìë™ ë©”íŠ¸ë¦­**: Token, latency ë“± ìë™ ìˆ˜ì§‘\n",
    "3. **í”„ë ˆì„ì›Œí¬ ì§€ì›**: LangChain, LlamaIndex, DSPy ë“±\n",
    "4. **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ë¹„ë™ê¸° ë¡œê¹… ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [MLflow Tracing Documentation](https://www.mlflow.org/docs/2.21.3/tracing/)\n",
    "- [LangChain Autolog](https://www.mlflow.org/docs/2.21.3/llms/langchain/)\n",
    "- [Tracing Concepts](https://www.mlflow.org/docs/2.21.3/tracing/#tracing-concepts)\n",
    "- [OpenTelemetry](https://opentelemetry.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
